{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertdc2/IS-170-Machine-Learning/blob/3.-Text-Mining-%26-NLP/Sanchez_HW3_Text_Mining_and_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BF9JybChGes"
      },
      "source": [
        "## **NLP book by Samuel Burns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iqUdPP_hPSg",
        "outputId": "83576374-4bee-40bb-c5d6-e8f580015f66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kcc-316kBMe",
        "outputId": "b17c03a7-ac55-4a34-91f2-39da6d7b1e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['There are multiple sentences in this string.', 'Today we are in IS170 working on lab 3.', 'Hopefully we finish on time.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "myString=\"There are multiple sentences while writing this string in todays homework. Right now i am working on the homework for lab 3. I hope to finish on time.\"\n",
        "\n",
        "tokenized_sentence = sent_tokenize(myString)\n",
        "print(tokenized_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8uzGxe-lS23",
        "outputId": "71088f10-658b-48da-cdac-456795de0c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['lets', 'try', 'this', 'command', 'which', 'splits', 'every', 'word', 'in', 'this', 'sentence']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "myString=\"lets try this command which splits every word in this sentence\"\n",
        "print(myString.split())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8zwXF0-sKmZ",
        "outputId": "0d94830a-8595-4905-c5c9-950cc2d44c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'function', 'will', 'tokenize', 'three', 'sentences', 'this', 'is', 'the', 'second', 'one', 'and', 'this', 'is', 'the', 'third', 'one']\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize, regexp_tokenize\n",
        "myString=\"This function will tokenize three sentences. this is the second one. and this is the third one\"\n",
        "\n",
        "print(regexp_tokenize(myString, pattern=\"\\w+\"))\n",
        "print(regexp_tokenize(myString, pattern=\"\\d+\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Jj2ri35s1q",
        "outputId": "077fa313-4935-4fa4-fba2-9d1a7161bd5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter=PorterStemmer()\n",
        "print(porter.stem(\"driving\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfM6K0fOC873",
        "outputId": "78a7fe6c-4d16-4770-ad65-00768fd32c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eat\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "lancaster=LancasterStemmer()\n",
        "print(lancaster.stem(\"speaking\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQxFxmxYD75D",
        "outputId": "6a1291bc-15a9-45e1-e165-2acdaebff670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "danc\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "snowball=SnowballStemmer(\"english\")\n",
        "print(snowball.stem(\"Diving\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3s1ywVjuUcA",
        "outputId": "d897c25a-a15c-46b4-eead-7b39fa9365f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hair\n",
            "rat\n",
            "pie\n",
            "third\n",
            "spell\n"
          ]
        }
      ],
      "source": [
        "# Lemmatization takes the word's meaning and converts to its base form\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "lemma=WordNetLemmatizer()\n",
        "print(lemma.lemmatize(\"hairs\"))\n",
        "print(lemma.lemmatize(\"rats\"))\n",
        "print(lemma.lemmatize(\"pies\"))\n",
        "print(lemma.lemmatize(\"thirds\"))\n",
        "print(lemma.lemmatize(\"spells\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u16GKPu_NHxh",
        "outputId": "e49cdd25-8eeb-48aa-a2eb-c51ed4dfa65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'stopward', 'command', 'rids', 'unneccassary', 'words,', 'speeds', 'process', 'get', 'main', 'points.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# The stopword command removes any words that do not add any meaning and are considered background noise.\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "mylist=stopwords.words('english')\n",
        "paragraph=\"I created this sentence to see which words get deleted that are seen as unecessary for this sentence exanple.\" \n",
        "postPa=[word for word in paragraph.split() if word not in mylist]\n",
        "print(postPa)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhCh3U3VwkxR",
        "outputId": "9cb13093-eb39-4d93-d446-e754312f305a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this command lower cases all words in the string ie: france germany china india.\n"
          ]
        }
      ],
      "source": [
        "myString = \"This command lower cases all words in the string ie: Brazil Japan Korea Africa.\"\n",
        "str=myString.lower()\n",
        "print(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cguplimaytP5",
        "outputId": "ab513abf-907c-4b3b-edc5-f8d602a57312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THIS COMMAND PUTS ALL WORDS IN THE STRING IN UPPERCASE.\n"
          ]
        }
      ],
      "source": [
        "myString = \"Countries i would like to travel are japan brazil korea italy.\"\n",
        "str=myString.upper()\n",
        "print(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkYlutlSzyaG",
        "outputId": "ec7a56f8-8693-4949-ccd5-40b656b34bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box A has   red and   white balls, while Box B has   red and   blue balls.\n"
          ]
        }
      ],
      "source": [
        "# This command removes all numbers in the string\n",
        "import re\n",
        "myString = 'Box A has 400 red and 600 white balls, while Box B has 300 red and 800 blue balls.'\n",
        "output = re.sub(r'\\d+', \" \", myString)\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyuhFax156Up",
        "outputId": "2ed73491-7419-42dc-b038-5829d2e0387d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what are we eating today with manypunctuation marks\n"
          ]
        }
      ],
      "source": [
        "#This command removes all puncuation marks\n",
        "import string\n",
        "myString = \"what are we eating today? {with} many.punctuation.? marks!!!!\"\n",
        "output = myString.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHvo4zIH9KJf",
        "outputId": "1e014fdb-1248-47c1-c10b-7d75ba2a80e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a sample string for the homework\n"
          ]
        }
      ],
      "source": [
        "#This command removes all whitespaces and tabs\n",
        "import string\n",
        "myString = \"\\t a sample string for the homework\\t\"\n",
        "str=myString.strip()\n",
        "print(str)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEJvEbLJp8xm"
      },
      "source": [
        "# We'll skip the \"Part of Speech Tagging\" and \"Named entity recognition\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOLX-wlLnzVu",
        "outputId": "1cdc62fc-05e2-4b6b-fc4c-a8b9fefa3a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('quick.n.01'), Synset('quick.s.01'), Synset('flying.s.02'), Synset('agile.s.01'), Synset('quick.s.04'), Synset('immediate.s.05'), Synset('quick.s.06'), Synset('promptly.r.01')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "syn = wordnet.synsets(\"quick\")\n",
        "print(syn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkyF1s43seJQ",
        "outputId": "05f42227-135b-4a8f-deec-1bdc5566a830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'passive_voice'}\n",
            "{'active_voice'}\n",
            "{'passive_voice', 'passive'}\n",
            "{'active_voice', 'active'}\n",
            "{'peaceful', 'passive_voice', 'inactive', 'passive'}\n",
            "{'active_voice', 'active'}\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet\n",
        "synonyms = []\n",
        "antonyms = []\n",
        "for s in wordnet.synsets(\"passive\"):\n",
        "  for lemm in s.lemmas():\n",
        "    synonyms.append(lemm.name())\n",
        "    if lemm.antonyms():\n",
        "      antonyms.append(lemm.antonyms()[0].name())\n",
        "\n",
        "      print(set(synonyms))\n",
        "      print(set(antonyms))\n",
        "\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMYAqnBSAV0C"
      },
      "source": [
        "Fixing Word Lengthening and Spell Correction requires additional library (pattern library) to be installed in order to run these topics. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iySsglW7wylw",
        "outputId": "e835c465-33bf-4f66-e408-a174e6b4f516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finally\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def reduce_lengthening(text):\n",
        "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
        "    return pattern.sub(r\"\\1\\1\", text)\n",
        "\n",
        "print(reduce_lengthening(\"finalllllllly\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "EGSSIXu5ykZP",
        "outputId": "39b79225-6e55-4871-90ea-f7b211f0b1cf"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-32c2d138d4c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspelling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"amazzzzziiiiiing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mword_wlf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_lengthening\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword_wlf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pattern'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pattern.en import spelling\n",
        "\n",
        "word=\"amazzzzziiiiiing\"\n",
        "word_wlf=reduce_lengthening(word) \n",
        "print (word_wlf) \n",
        "\n",
        "correct_word=spelling(word_wlf)\n",
        "print (correct_word)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQWkxrd5CDg1"
      },
      "source": [
        "# Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maQtbb2TCJ3F",
        "outputId": "f3876a8a-3bfa-4884-f3ce-71524236abe4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(['capsule', ':', 'the', 'world', 'will', 'come', 'to', 'an', 'end', 'at', 'midnight', '.', 'everyone', 'knows', 'it', 'and', 'must', 'make', 'a', 'final', 'peace', 'with', 'the', 'last', 'hours', 'of', 'their', 'lives', '.', 'this', 'is', 'an', 'intelligent', 'science', 'fiction', 'film', 'with', 'no', 'special', 'effects', ',', 'just', 'personalities', 'and', 'ideas', '.', ',', 'high', '+', '2', '(', '-', '4', 'to', '+', '4', ')', '-', 'it', 'is', 'the', 'last', 'night', 'of', 'the', 'planet', 'and', 'several', 'different', 'people', 'are', 'reacting', 'each', 'in', 'their', 'own', 'way', 'to', 'the', 'end', '.', 'the', 'film', 'covers', '6', 'pm', 'to', 'midnight', '.', 'the', 'main', 'character', 'is', 'patrick', 'played', 'by', 'david', 'mckellan', 'who', 'also', 'wrote', 'and', 'directed', '.', '-', 'reminiscent', 'of', 'on', 'the', 'beach', '.', 'but', 'much', 'more', 'so', 'of', 'a', 'story', 'richard', 'matheson', 'wrote', ',', '\"', 'the', 'last', 'day', '.', '\"', '(', 'p', '.', 's', '.', 'on', 'rereading', 'the', '1953', 'matheson', ',', 'this', 'film', 'is', 'almost', 'a', 'loose', 'adaptation', 'of', 'that', 'story', '.', 'the', 'similarities', 'may', 'be', 'mere', 'coincidence', ',', 'but', 'they', 'are', 'numerous', 'and', 'they', 'are', 'very', 'striking', '.', ')', '-', 'us', 'release', 'may', 'be', 'problematical', '.', 'the', 'title', 'is', 'lackluster', 'and', 'non', '-', 'memorable', ',', 'though', 'very', 'appropriate', 'when', 'you', 'know', 'about', 'the', 'film', '.', 'also', 'provincial', 'americans', 'may', 'not', 'care', 'about', 'the', 'end', 'of', 'the', 'world', 'coming', 'to', 'toronto', '.', 'they', 'probably', 'would', 'feel', 'it', 'would', 'not', 'affect', 'them', '.', 'perhaps', 'a', 'pbs', 'release', 'would', 'be', 'possible', '.', '-', 'patrick', \"'\", 's', 'family', 'has', 'declared', 'it', 'christmas', 'and', 'are', 'hurt', 'that', 'the', '(', 'adult', ')', 'children', 'will', 'not', 'spend', 'the', 'whole', 'evening', 'with', 'them', '.', '-', 'grocery', 'stores', 'mostly', 'looted', '.', 'it', 'seems', 'though', 'that', 'one', 'of', 'everything', 'is', 'left', '.', '-', 'some', 'people', 'continue', 'business', 'as', 'usual', ',', 'some', 'want', 'sex', ',', 'some', 'react', 'with', 'religion', ',', 'some', 'riot', '.', 'some', 'people', 'are', 'in', 'total', 'denial', '.', '-', 'much', 'comedy', ',', 'much', 'drama', '.', '-', 'very', 'canadian', 'cast', '.', '-', 'it', 'does', 'not', 'get', 'dark', '.', 'it', 'is', 'just', 'always', 'daytime', '.', '-', 'radio', 'playing', '\"', 'last', 'night', 'i', 'didn', \"'\", 't', 'get', 'to', 'sleep', 'at', 'all', '.', '\"', 'how', 'appropriate', '.', '-', 'david', 'cronenberg', 'as', 'a', 'kind', 'of', 'bland', 'functionary', 'manager', 'at', 'the', 'gas', 'company', '.', 'genvieve', 'bujold', 'as', 'french', 'teacher', 'visiting', 'former', 'student', '.', '-', 'science', 'fiction', 'film', 'with', 'no', 'special', 'effects', ',', 'cost', 'about', 'two', 'million', 'dollars', '.', '-', 'the', 'person', 'you', 'have', 'been', 'thrown', 'together', 'with', 'by', 'chance', 'becomes', 'the', 'most', 'important', 'person', 'to', 'you', 'for', 'the', 'rest', 'of', 'your', 'life', '.', '-', 'why', 'would', 'it', 'be', 'so', 'precisely', 'at', 'midnight', '?', 'what', 'about', 'other', 'time', 'zones', '?', 'what', 'is', 'the', 'nature', 'of', 'what', 'is', 'destroying', 'the', 'world', '?'], 'pos')\n",
            "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
            "211\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import random\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "nltk.download('movie_reviews')\n",
        "docs=[(list(movie_reviews.words(fileid)), category)\n",
        "      for category in movie_reviews.categories()\n",
        "      for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "random.shuffle(docs)\n",
        "\n",
        "print(docs[1])\n",
        "\n",
        "all=[]\n",
        "for w in movie_reviews.words():\n",
        "  all.append(w.lower())\n",
        "\n",
        "all=nltk.FreqDist(all)\n",
        "print(all.most_common(15))\n",
        "print(all[\"entertainment\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5b1lBA1mjCn",
        "outputId": "f90815d7-ee5e-4a37-e744-7ff4d624257b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(['frequency', 'n', '.', ',', 'the', 'number', 'of', 'times', 'a', 'specified', 'phenomenon', 'occurs', 'within', 'a', 'specified', 'interval', 'as', 'the', 'number', 'of', 'repetitions', 'of', 'a', 'complete', 'sequence', 'of', 'values', 'of', 'a', 'periodic', 'function', 'per', 'unit', 'variation', 'of', 'an', 'independent', 'variable', '?', 'etc', 'don', \"'\", 't', 'worry', '.', 'when', 'watching', 'the', 'thriller', 'frequency', ',', 'you', 'won', \"'\", 't', 'have', 'to', 'know', 'what', 'the', 'heck', 'frequency', 'means', '.', 'the', 'premise', ',', 'although', 'it', 'may', 'sound', 'complex', ',', 'is', 'very', 'basic', 'on', 'the', 'big', 'screen', '.', 'a', 'new', 'york', 'cop', ',', 'john', ',', '(', 'jim', 'caviezel', ')', 'finds', 'a', 'radio', 'in', 'his', 'house', ',', 'which', 'allows', 'him', 'to', 'communicate', 'with', 'his', 'new', 'york', 'firefighter', 'father', ',', 'frank', ',', '(', 'dennis', 'quaid', ')', 'who', 'died', 'thirty', 'years', 'ago', '.', 'immediately', 'john', 'warns', 'his', 'father', 'that', 'he', 'will', 'die', 'trying', 'to', 'stop', 'a', 'fire', 'in', 'an', 'abandoned', 'warehouse', '.', 'when', 'frank', 'takes', 'his', 'advice', 'and', 'survives', 'the', 'accident', 'he', 'wasn', \"'\", 't', 'supposed', 'to', ',', 'the', 'two', 'eventually', 'realize', 'that', 'by', 'changing', 'that', 'one', 'moment', 'in', 'the', 'past', ',', 'they', 'have', 'created', 'a', 'whole', 'new', 'future', 'in', 'which', 'a', 'serial', 'killer', 'murders', 'john', \"'\", 's', 'mother', 'and', 'nine', 'other', 'women', '.', 'it', 'is', 'now', 'up', 'to', 'john', 'and', 'frank', 'to', 'use', 'their', 'special', 'connection', 'and', 'save', 'thirty', 'years', 'ago', 'to', 'make', 'present', 'time', 'a', 'better', 'place', '.', '(', 'i', 'told', 'you', 'that', 'wasn', \"'\", 't', 'confusing', '?', ')', '.', 'overall', ',', 'i', 'was', 'very', 'pleased', 'with', 'frequency', '.', 'it', \"'\", 's', 'occasional', 'sappy', 'moments', 'perfectly', 'synchronized', 'with', 'its', 'suspenseful', 'serial', 'killer', 'scenes', '.', 'i', 'usually', 'don', \"'\", 't', 'buy', 'those', 'cheesy', '\"', 'i', 'love', 'you', 'dad', '\"', 'segments', 'in', 'movies', ',', 'but', 'this', 'one', 'surprisingly', 'satisfied', 'me', '.', 'maybe', 'because', 'the', 'plot', 'is', 'so', 'creative', 'and', 'universal', 'that', 'i', 'believed', 'that', 'this', 'is', 'how', 'most', 'people', 'would', 'act', 'when', 'talking', 'to', 'a', 'dead', 'relative', '.', 'frequency', \"'\", 's', 'creepy', 'premise', 'left', 'me', 'thinking', 'once', 'the', 'film', 'ended', ',', 'what', 'if', '?', 'what', 'would', 'i', 'do', '?', 'would', 'i', 'help', 'my', 'own', 'family', 'or', 'save', 'a', 'historical', 'figure', 'from', 'being', 'assasinated', '?', 'or', 'stop', 'some', 'kids', 'from', 'shooting', 'other', 'kids', '?', 'or', 'buy', 'stock', 'from', 'yahoo', '!', '?', '(', 'a', 'character', 'in', 'the', 'film', 'does', 'the', 'latter', 'with', 'humorous', 'consequences', ')', '.', 'frequency', 'also', 'reminded', 'me', 'of', 'the', 'fantastic', 'back', 'to', 'the', 'future', '.', 'both', 'share', 'that', '\"', 'change', 'the', 'past', 'slightly', ',', 'and', 'you', \"'\", 'll', 'change', 'the', 'future', 'heavily', '\"', 'warning', '.', 'the', 'changes', 'between', 'the', 'present', 'and', 'the', 'past', ',', 'such', 'as', 'different', 'newspaper', 'headlines', 'or', 'people', 'disappearing', 'and', 'reappearing', 'in', 'photographs', ',', 'are', 'very', 'similar', '.', 'both', 'are', 'also', 'wonderful', 'feel', '-', 'good', 'family', 'films', 'that', 'can', 'attract', 'to', 'a', 'number', 'of', 'generations', '.', 'the', 'only', 'difference', 'worth', 'noting', 'is', 'that', 'frequency', \"'\", 's', 'final', 'scene', 'doesn', \"'\", 't', 'set', 'up', 'a', 'possibility', 'for', 'a', 'lucrative', 'sequel', 'already', 'in', 'the', 'making', '.', 'there', 'are', 'some', 'problems', 'with', 'the', 'film', 'though', '.', 'first', ',', 'there', 'is', 'a', 'major', 'flaw', 'in', 'the', 'story', 'towards', 'the', 'end', 'that', 'is', 'somewhat', 'distracting', '(', 'email', 'me', 'if', 'you', 'have', 'seen', 'the', 'movie', 'and', 'want', 'to', 'know', 'what', 'i', 'think', 'it', 'is', ')', '.', 'the', 'plot', 'must', 'have', 'confused', 'even', 'the', 'filmmakers', 'who', 'frequently', '(', 'no', 'pun', 'intended', ')', 'switch', 'from', '1969', 'to', '1999', 'while', 'telling', 'the', 'story', '.', 'another', 'problem', 'is', 'that', 'the', 'supporting', 'cast', ',', 'including', 'noah', 'emmerich', 'and', 'andre', 'braugher', ',', 'are', 'underused', '.', 'while', 'in', 'the', 'film', ',', 'which', 'is', 'not', 'enough', ',', 'the', 'aforementioned', 'actors', 'steal', 'every', 'scene', 'they', 'are', 'in', '.', 'frequency', 'was', 'a', 'pleasant', 'surprise', 'for', 'me', 'and', 'the', 'audience', 'i', 'saw', 'it', 'with', 'who', 'cheered', 'at', 'the', 'end', '.', 'even', 'if', 'you', 'know', 'what', 'is', 'going', 'to', 'happen', 'or', 'if', 'you', 'think', 'the', 'preview', 'ruined', 'the', 'movie', 'for', 'you', ',', 'like', 'it', 'almost', 'did', 'for', 'me', ',', 'check', 'this', 'movie', 'out', '.', 'you', 'may', 'be', 'surprised', 'as', 'well', '.'], 'pos')\n",
            "{'plot': True, ':': True, 'two': True, 'teen': True, 'couples': True, 'go': True, 'to': True, 'a': True, 'church': True, 'party': True, ',': True, 'drink': True, 'and': True, 'then': True, 'drive': True, '.': True, 'they': True, 'get': True, 'into': True, 'an': True, 'accident': True, 'one': True, 'of': True, 'the': True, 'guys': True, 'dies': True, 'but': True, 'his': True, 'girlfriend': True, 'continues': True, 'see': True, 'him': True, 'in': True, 'her': True, 'life': True, 'has': True, 'nightmares': True, 'what': True, \"'\": True, 's': True, 'deal': True, '?': True, 'watch': True, 'movie': True, '\"': True, 'sorta': True, 'find': True, 'out': True, 'critique': True, 'mind': True, '-': True, 'fuck': True, 'for': True, 'generation': True, 'that': True, 'touches': True, 'on': True, 'very': True, 'cool': True, 'idea': True, 'presents': True, 'it': True, 'bad': True, 'package': True, 'which': True, 'is': True, 'makes': True, 'this': True, 'review': True, 'even': True, 'harder': True, 'write': True, 'since': True, 'i': True, 'generally': True, 'applaud': True, 'films': True, 'attempt': True, 'break': True, 'mold': True, 'mess': True, 'with': True, 'your': True, 'head': True, 'such': True, '(': True, 'lost': True, 'highway': True, '&': True, 'memento': True, ')': True, 'there': True, 'are': True, 'good': True, 'ways': True, 'making': True, 'all': True, 'types': True, 'these': True, 'folks': True, 'just': True, 'didn': True, 't': True, 'snag': True, 'correctly': True, 'seem': True, 'have': True, 'taken': True, 'pretty': True, 'neat': True, 'concept': True, 'executed': True, 'terribly': True, 'so': True, 'problems': True, 'well': True, 'its': True, 'main': True, 'problem': True, 'simply': True, 'too': True, 'jumbled': True, 'starts': True, 'off': True, 'normal': True, 'downshifts': True, 'fantasy': True, 'world': True, 'you': True, 'as': True, 'audience': True, 'member': True, 'no': True, 'going': True, 'dreams': True, 'characters': True, 'coming': True, 'back': True, 'from': True, 'dead': True, 'others': True, 'who': True, 'look': True, 'like': True, 'strange': True, 'apparitions': True, 'disappearances': True, 'looooot': True, 'chase': True, 'scenes': True, 'tons': True, 'weird': True, 'things': True, 'happen': True, 'most': True, 'not': True, 'explained': True, 'now': True, 'personally': True, 'don': True, 'trying': True, 'unravel': True, 'film': True, 'every': True, 'when': True, 'does': True, 'give': True, 'me': True, 'same': True, 'clue': True, 'over': True, 'again': True, 'kind': True, 'fed': True, 'up': True, 'after': True, 'while': True, 'biggest': True, 'obviously': True, 'got': True, 'big': True, 'secret': True, 'hide': True, 'seems': True, 'want': True, 'completely': True, 'until': True, 'final': True, 'five': True, 'minutes': True, 'do': True, 'make': True, 'entertaining': True, 'thrilling': True, 'or': True, 'engaging': True, 'meantime': True, 'really': True, 'sad': True, 'part': True, 'arrow': True, 'both': True, 'dig': True, 'flicks': True, 'we': True, 'actually': True, 'figured': True, 'by': True, 'half': True, 'way': True, 'point': True, 'strangeness': True, 'did': True, 'start': True, 'little': True, 'bit': True, 'sense': True, 'still': True, 'more': True, 'guess': True, 'bottom': True, 'line': True, 'movies': True, 'should': True, 'always': True, 'sure': True, 'before': True, 'given': True, 'password': True, 'enter': True, 'understanding': True, 'mean': True, 'showing': True, 'melissa': True, 'sagemiller': True, 'running': True, 'away': True, 'visions': True, 'about': True, '20': True, 'throughout': True, 'plain': True, 'lazy': True, '!': True, 'okay': True, 'people': True, 'chasing': True, 'know': True, 'need': True, 'how': True, 'giving': True, 'us': True, 'different': True, 'offering': True, 'further': True, 'insight': True, 'down': True, 'apparently': True, 'studio': True, 'took': True, 'director': True, 'chopped': True, 'themselves': True, 'shows': True, 'might': True, 've': True, 'been': True, 'decent': True, 'here': True, 'somewhere': True, 'suits': True, 'decided': True, 'turning': True, 'music': True, 'video': True, 'edge': True, 'would': True, 'actors': True, 'although': True, 'wes': True, 'bentley': True, 'seemed': True, 'be': True, 'playing': True, 'exact': True, 'character': True, 'he': True, 'american': True, 'beauty': True, 'only': True, 'new': True, 'neighborhood': True, 'my': True, 'kudos': True, 'holds': True, 'own': True, 'entire': True, 'feeling': True, 'unraveling': True, 'overall': True, 'doesn': True, 'stick': True, 'because': True, 'entertain': True, 'confusing': True, 'rarely': True, 'excites': True, 'feels': True, 'redundant': True, 'runtime': True, 'despite': True, 'ending': True, 'explanation': True, 'craziness': True, 'came': True, 'oh': True, 'horror': True, 'slasher': True, 'flick': True, 'packaged': True, 'someone': True, 'assuming': True, 'genre': True, 'hot': True, 'kids': True, 'also': True, 'wrapped': True, 'production': True, 'years': True, 'ago': True, 'sitting': True, 'shelves': True, 'ever': True, 'whatever': True, 'skip': True, 'where': True, 'joblo': True, 'nightmare': True, 'elm': True, 'street': True, '3': True, '7': True, '/': True, '10': True, 'blair': True, 'witch': True, '2': True, 'crow': True, '9': True, 'salvation': True, '4': True, 'stir': True, 'echoes': True, '8': True, 'happy': False, 'bastard': False, 'quick': False, 'damn': False, 'y2k': False, 'bug': False, 'starring': False, 'jamie': False, 'lee': False, 'curtis': False, 'another': False, 'baldwin': False, 'brother': False, 'william': False, 'time': False, 'story': False, 'regarding': False, 'crew': False, 'tugboat': False, 'comes': False, 'across': False, 'deserted': False, 'russian': False, 'tech': False, 'ship': False, 'kick': False, 'power': False, 'within': False, 'gore': False, 'bringing': False, 'few': False, 'action': False, 'sequences': False, 'virus': False, 'empty': False, 'flash': False, 'substance': False, 'why': False, 'was': False, 'middle': False, 'nowhere': False, 'origin': False, 'pink': False, 'flashy': False, 'thing': False, 'hit': False, 'mir': False, 'course': False, 'donald': False, 'sutherland': False, 'stumbling': False, 'around': False, 'drunkenly': False, 'hey': False, 'let': False, 'some': False, 'robots': False, 'acting': False, 'below': False, 'average': False, 'likes': False, 're': False, 'likely': False, 'work': False, 'halloween': False, 'h20': False, 'wasted': False, 'real': False, 'star': False, 'stan': False, 'winston': False, 'robot': False, 'design': False, 'schnazzy': False, 'cgi': False, 'occasional': False, 'shot': False, 'picking': False, 'brain': False, 'if': False, 'body': False, 'parts': False, 'turn': False, 'otherwise': False, 'much': False, 'sunken': False, 'jaded': False, 'viewer': False, 'thankful': False, 'invention': False, 'timex': False, 'indiglo': False, 'based': False, 'late': False, '1960': False, 'television': False, 'show': False, 'name': False, 'mod': False, 'squad': False, 'tells': False, 'tale': False, 'three': False, 'reformed': False, 'criminals': False, 'under': False, 'employ': False, 'police': False, 'undercover': False, 'however': False, 'wrong': False, 'evidence': False, 'gets': False, 'stolen': False, 'immediately': False, 'suspicion': False, 'ads': False, 'cuts': False, 'claire': False, 'dane': False, 'nice': False, 'hair': False, 'cute': False, 'outfits': False, 'car': False, 'chases': False, 'stuff': False, 'blowing': False, 'sounds': False, 'first': False, 'fifteen': False, 'quickly': False, 'becomes': False, 'apparent': False, 'certainly': False, 'slick': False, 'looking': False, 'complete': False, 'costumes': False, 'isn': False, 'enough': False, 'best': False, 'described': False, 'cross': False, 'between': False, 'hour': False, 'long': False, 'cop': False, 'stretched': False, 'span': False, 'single': False, 'clich': False, 'matter': False, 'elements': False, 'recycled': False, 'everything': False, 'already': False, 'seen': False, 'nothing': False, 'spectacular': False, 'sometimes': False, 'bordering': False, 'wooden': False, 'danes': False, 'omar': False, 'epps': False, 'deliver': False, 'their': False, 'lines': False, 'bored': False, 'transfers': False, 'onto': False, 'escape': False, 'relatively': False, 'unscathed': False, 'giovanni': False, 'ribisi': False, 'plays': False, 'resident': False, 'crazy': False, 'man': False, 'ultimately': False, 'being': False, 'worth': False, 'watching': False, 'unfortunately': False, 'save': False, 'convoluted': False, 'apart': False, 'occupying': False, 'screen': False, 'young': False, 'cast': False, 'clothes': False, 'hip': False, 'soundtrack': False, 'appears': False, 'geared': False, 'towards': False, 'teenage': False, 'mindset': False, 'r': False, 'rating': False, 'content': False, 'justify': False, 'juvenile': False, 'older': False, 'information': False, 'literally': False, 'spoon': False, 'hard': False, 'instead': False, 'telling': False, 'dialogue': False, 'poorly': False, 'written': False, 'extremely': False, 'predictable': False, 'progresses': False, 'won': False, 'care': False, 'heroes': False, 'any': False, 'jeopardy': False, 'll': False, 'aren': False, 'basing': False, 'nobody': False, 'remembers': False, 'questionable': False, 'wisdom': False, 'especially': False, 'considers': False, 'target': False, 'fact': False, 'number': False, 'memorable': False, 'can': False, 'counted': False, 'hand': False, 'missing': False, 'finger': False, 'times': False, 'checked': False, 'six': False, 'clear': False, 'indication': False, 'them': False, 'than': False, 'cash': False, 'spending': False, 'dollar': False, 'judging': False, 'rash': False, 'awful': False, 'seeing': False, 'avoid': False, 'at': False, 'costs': False, 'quest': False, 'camelot': False, 'warner': False, 'bros': False, 'feature': False, 'length': False, 'fully': False, 'animated': False, 'steal': False, 'clout': False, 'disney': False, 'cartoon': False, 'empire': False, 'mouse': False, 'reason': False, 'worried': False, 'other': False, 'recent': False, 'challenger': False, 'throne': False, 'last': False, 'fall': False, 'promising': False, 'flawed': False, '20th': False, 'century': False, 'fox': False, 'anastasia': False, 'hercules': False, 'lively': False, 'colorful': False, 'palate': False, 'had': False, 'beat': False, 'hands': False, 'crown': False, '1997': False, 'piece': False, 'animation': False, 'year': False, 'contest': False, 'arrival': False, 'magic': False, 'kingdom': False, 'mediocre': False, '--': False, 'd': False, 'pocahontas': False, 'those': False, 'keeping': False, 'score': False, 'nearly': False, 'dull': False, 'revolves': False, 'adventures': False, 'free': False, 'spirited': False, 'kayley': False, 'voiced': False, 'jessalyn': False, 'gilsig': False, 'early': False, 'daughter': False, 'belated': False, 'knight': False, 'king': False, 'arthur': False, 'round': False, 'table': False, 'dream': False, 'follow': False, 'father': False, 'footsteps': False, 'she': False, 'chance': False, 'evil': False, 'warlord': False, 'ruber': False, 'gary': False, 'oldman': False, 'ex': False, 'gone': False, 'steals': False, 'magical': False, 'sword': False, 'excalibur': False, 'accidentally': False, 'loses': False, 'dangerous': False, 'booby': False, 'trapped': False, 'forest': False, 'help': False, 'hunky': False, 'blind': False, 'timberland': False, 'dweller': False, 'garrett': False, 'carey': False, 'elwes': False, 'headed': False, 'dragon': False, 'eric': False, 'idle': False, 'rickles': False, 'arguing': False, 'itself': False, 'able': False, 'medieval': False, 'sexist': False, 'prove': False, 'fighter': False, 'side': False, 'pure': False, 'showmanship': False, 'essential': False, 'element': False, 'expected': False, 'climb': False, 'high': False, 'ranks': False, 'differentiates': False, 'something': False, 'saturday': False, 'morning': False, 'subpar': False, 'instantly': False, 'forgettable': False, 'songs': False, 'integrated': False, 'computerized': False, 'footage': False, 'compare': False, 'run': False, 'angry': False, 'ogre': False, 'herc': False, 'battle': False, 'hydra': False, 'rest': False, 'case': False, 'stink': False, 'none': False, 'remotely': False, 'interesting': False, 'race': False, 'bland': False, 'end': False, 'tie': False, 'win': False, 'comedy': False, 'shtick': False, 'awfully': False, 'cloying': False, 'least': False, 'signs': False, 'pulse': False, 'fans': False, \"-'\": False, '90s': False, 'tgif': False, 'will': False, 'thrilled': False, 'jaleel': False, 'urkel': False, 'white': False, 'bronson': False, 'balki': False, 'pinchot': False, 'sharing': False, 'nicely': False, 'realized': False, 'though': False, 'm': False, 'loss': False, 'recall': False, 'specific': False, 'providing': False, 'voice': False, 'talent': False, 'enthusiastic': False, 'paired': False, 'singers': False, 'sound': False, 'musical': False, 'moments': False, 'jane': False, 'seymour': False, 'celine': False, 'dion': False, 'must': False, 'strain': False, 'through': False, 'aside': False, 'children': False, 'probably': False, 'adults': False, 'grievous': False, 'error': False, 'lack': False, 'personality': False, 'learn': False, 'goes': False, 'synopsis': False, 'mentally': False, 'unstable': False, 'undergoing': False, 'psychotherapy': False, 'saves': False, 'boy': False, 'potentially': False, 'fatal': False, 'falls': False, 'love': False, 'mother': False, 'fledgling': False, 'restauranteur': False, 'unsuccessfully': False, 'attempting': False, 'gain': False, 'woman': False, 'favor': False, 'takes': False, 'pictures': False, 'kills': False, 'comments': False, 'stalked': False, 'yet': False, 'seemingly': False, 'endless': False, 'string': False, 'spurned': False, 'psychos': False, 'getting': False, 'revenge': False, 'type': False, 'stable': False, 'category': False, '1990s': False, 'industry': False, 'theatrical': False, 'direct': False, 'proliferation': False, 'may': False, 'due': False, 'typically': False, 'inexpensive': False, 'produce': False, 'special': False, 'effects': False, 'stars': False, 'serve': False, 'vehicles': False, 'nudity': False, 'allowing': False, 'frequent': False, 'night': False, 'cable': False, 'wavers': False, 'slightly': False, 'norm': False, 'respect': False, 'psycho': False, 'never': False, 'affair': False, ';': False, 'contrary': False, 'rejected': False, 'rather': False, 'lover': False, 'wife': False, 'husband': False, 'entry': False, 'doomed': False, 'collect': False, 'dust': False, 'viewed': False, 'midnight': False, 'provide': False, 'suspense': False, 'sets': False, 'interspersed': False, 'opening': False, 'credits': False, 'instance': False, 'serious': False, 'sounding': False, 'narrator': False, 'spouts': False, 'statistics': False, 'stalkers': False, 'ponders': False, 'cause': False, 'stalk': False, 'implicitly': False, 'implied': False, 'men': False, 'shown': False, 'snapshot': False, 'actor': False, 'jay': False, 'underwood': False, 'states': False, 'daryl': False, 'gleason': False, 'stalker': False, 'brooke': False, 'daniels': False, 'meant': False, 'called': False, 'guesswork': False, 'required': False, 'proceeds': False, 'begins': False, 'obvious': False, 'sequence': False, 'contrived': False, 'quite': False, 'brings': False, 'victim': False, 'together': False, 'obsesses': False, 'follows': False, 'tries': False, 'woo': False, 'plans': False, 'become': False, 'desperate': False, 'elaborate': False, 'include': False, 'cliche': False, 'murdered': False, 'pet': False, 'require': False, 'found': False, 'exception': False, 'cat': False, 'shower': False, 'events': False, 'lead': False, 'inevitable': False, 'showdown': False, 'survives': False, 'invariably': False, 'conclusion': False, 'turkey': False, 'uniformly': False, 'adequate': False, 'anything': False, 'home': False, 'either': False, 'turns': False, 'toward': False, 'melodrama': False, 'overdoes': False, 'words': False, 'manages': False, 'creepy': False, 'pass': False, 'demands': False, 'maryam': False, 'abo': False, 'close': False, 'played': False, 'bond': False, 'chick': False, 'living': False, 'daylights': False, 'equally': False, 'title': False, 'ditzy': False, 'strong': False, 'independent': False, 'business': False, 'owner': False, 'needs': False, 'proceed': False, 'example': False, 'suspicions': False, 'ensure': False, 'use': False, 'excuse': False, 'decides': False, 'return': False, 'toolbox': False, 'left': False, 'place': False, 'house': False, 'leave': False, 'door': False, 'answers': False, 'opens': False, 'wanders': False, 'returns': False, 'enters': False, 'our': False, 'heroine': False, 'danger': False, 'somehow': False, 'parked': False, 'front': False, 'right': False, 'oblivious': False, 'presence': False, 'inside': False, 'whole': False, 'episode': False, 'places': False, 'incredible': False, 'suspension': False, 'disbelief': False, 'questions': False, 'validity': False, 'intelligence': False, 'receives': False, 'highly': False, 'derivative': False, 'somewhat': False, 'boring': False, 'cannot': False, 'watched': False, 'rated': False, 'mostly': False, 'several': False, 'murder': False, 'brief': False, 'strip': False, 'bar': False, 'offensive': False, 'many': False, 'thrillers': False, 'mood': False, 'stake': False, 'else': False, 'capsule': False, '2176': False, 'planet': False, 'mars': False, 'taking': False, 'custody': False, 'accused': False, 'murderer': False, 'face': False, 'menace': False, 'lot': False, 'fighting': False, 'john': False, 'carpenter': False, 'reprises': False, 'ideas': False, 'previous': False, 'assault': False, 'precinct': False, '13': False, 'homage': False, 'himself': False, '0': False, '+': False, 'believes': False, 'fight': False, 'horrible': False, 'writer': False, 'supposedly': False, 'expert': False, 'mistake': False, 'ghosts': False, 'drawn': False, 'humans': False, 'surprisingly': False, 'low': False, 'powered': False, 'alien': False, 'addition': False, 'anybody': False, 'made': False, 'grounds': False, 'sue': False, 'chock': False, 'full': False, 'pieces': False, 'prince': False, 'darkness': False, 'surprising': False, 'managed': False, 'fit': False, 'admittedly': False, 'novel': False, 'science': False, 'fiction': False, 'experience': False, 'terraformed': False, 'walk': False, 'surface': False, 'without': False, 'breathing': False, 'gear': False, 'budget': False, 'mentioned': False, 'gravity': False, 'increased': False, 'earth': False, 'easier': False, 'society': False, 'changed': False, 'advanced': False, 'culture': False, 'women': False, 'positions': False, 'control': False, 'view': False, 'stagnated': False, 'female': False, 'beyond': False, 'minor': False, 'technological': False, 'advances': False, 'less': False, '175': False, 'expect': False, 'change': False, 'ten': False, 'basic': False, 'common': False, 'except': False, 'yes': False, 'replaced': False, 'tacky': False, 'rundown': False, 'martian': False, 'mining': False, 'colony': False, 'having': False, 'criminal': False, 'napolean': False, 'wilson': False, 'desolation': False, 'williams': False, 'facing': False, 'hoodlums': False, 'automatic': False, 'weapons': False, 'nature': False, 'behave': False, 'manner': False, 'essentially': False, 'human': False, 'savages': False, 'lapse': False, 'imagination': False, 'told': False, 'flashback': False, 'entirely': False, 'filmed': False, 'almost': False, 'tones': False, 'red': False, 'yellow': False, 'black': False, 'powerful': False, 'scene': False, 'train': False, 'rushing': False, 'heavy': False, 'sadly': False, 'buildup': False, 'terror': False, 'creates': False, 'looks': False, 'fugitive': False, 'wannabes': False, 'rock': False, 'band': False, 'kiss': False, 'building': False, 'bunch': False, 'sudden': False, 'jump': False, 'sucker': False, 'thinking': False, 'scary': False, 'happening': False, 'standard': False, 'haunted': False, 'shock': False, 'great': False, 'newer': False, 'unimpressive': False, 'digital': False, 'decapitations': False, 'fights': False, 'short': False, 'stretch': False, 'release': False, 'mission': False, 'panned': False, 'reviewers': False, 'better': False, 'rate': False, 'scale': False, 'following': False, 'showed': False, 'liked': False, 'moderately': False, 'classic': False, 'comment': False, 'twice': False, 'ask': False, 'yourself': False, '8mm': False, 'eight': False, 'millimeter': False, 'wholesome': False, 'surveillance': False, 'sight': False, 'values': False, 'becoming': False, 'enmeshed': False, 'seedy': False, 'sleazy': False, 'underworld': False, 'hardcore': False, 'pornography': False, 'bubbling': False, 'beneath': False, 'town': False, 'americana': False, 'sordid': False, 'sick': False, 'depraved': False, 'necessarily': False, 'stop': False, 'order': False, 'satisfy': False, 'twisted': False, 'desires': False, 'position': False, 'influence': False, 'kinds': False, 'demented': False, 'talking': False, 'snuff': False, 'supposed': False, 'documentaries': False, 'victims': False, 'brutalized': False, 'killed': False, 'camera': False, 'joel': False, 'schumacher': False, 'credit': False, 'batman': False, 'robin': False, 'kill': False, 'forever': False, 'client': False, 'thirds': False, 'unwind': False, 'fairly': False, 'conventional': False, 'persons': False, 'drama': False, 'albeit': False, 'particularly': False, 'unsavory': False, 'core': False, 'threatening': False, 'along': False, 'explodes': False, 'violence': False, 'think': False, 'finally': False, 'tags': False, 'ridiculous': False, 'self': False, 'righteous': False, 'finale': False, 'drags': False, 'unpleasant': False, 'trust': False, 'waste': False, 'hours': False, 'nicolas': False, 'snake': False, 'eyes': False, 'cage': False, 'private': False, 'investigator': False, 'tom': False, 'welles': False, 'hired': False, 'wealthy': False, 'philadelphia': False, 'widow': False, 'determine': False, 'whether': False, 'reel': False, 'safe': False, 'documents': False, 'girl': False, 'assignment': False, 'factly': False, 'puzzle': False, 'neatly': False, 'specialized': False, 'skills': False, 'training': False, 'easy': False, 'cops': False, 'toilet': False, 'tanks': False, 'clues': False, 'deeper': False, 'digs': False, 'investigation': False, 'obsessed': False, 'george': False, 'c': False, 'scott': False, 'paul': False, 'schrader': False, 'occasionally': False, 'flickering': False, 'whirs': False, 'sprockets': False, 'winding': False, 'projector': False, 'reminding': False, 'task': False, 'hints': False, 'toll': False, 'lovely': False, 'catherine': False, 'keener': False, 'frustrated': False, 'cleveland': False, 'ugly': False, 'split': False, 'level': False, 'harrisburg': False, 'pa': False, 'condemn': False, 'condone': False, 'subject': False, 'exploits': False, 'irony': False, 'seven': False, 'scribe': False, 'andrew': False, 'kevin': False, 'walker': False, 'vision': False, 'lane': False, 'limited': False, 'hollywood': False, 'product': False, 'snippets': False, 'covering': False, 'later': False, 'joaquin': False, 'phoenix': False, 'far': False, 'adult': False, 'bookstore': False, 'flunky': False, 'max': False, 'california': False, 'cover': False, 'horrid': False, 'screened': False, 'familiar': False, 'revelation': False, 'sexual': False, 'deviants': False, 'indeed': False, 'monsters': False, 'everyday': False, 'neither': False, 'super': False, 'nor': False, 'shocking': False, 'banality': False, 'exactly': False, 'felt': False, 'weren': False, 'nine': False, 'laughs': False, 'months': False, 'terrible': False, 'mr': False, 'hugh': False, 'grant': False, 'huge': False, 'dork': False, 'oral': False, 'sex': False, 'prostitution': False, 'referring': False, 'bugs': False, 'annoying': False, 'adam': False, 'sandler': False, 'jim': False, 'carrey': False, 'eye': False, 'flutters': False, 'nervous': False, 'smiles': False, 'slapstick': False, 'fistfight': False, 'delivery': False, 'room': False, 'culminating': False, 'joan': False, 'cusack': False, 'lap': False, 'paid': False, '$': False, '60': False, 'included': False, 'obscene': False, 'double': False, 'entendres': False, 'obstetrician': False, 'pregnant': False, 'pussy': False, 'size': False, 'hairs': False, 'coat': False, 'nonetheless': False, 'exchange': False, 'cookie': False, 'cutter': False, 'originality': False, 'humor': False, 'successful': False, 'child': False, 'psychiatrist': False, 'psychologist': False, 'scriptwriters': False, 'could': False, 'inject': False, 'unfunny': False, 'kid': False, 'dad': False, 'asshole': False, 'eyelashes': False, 'offers': False, 'smile': False, 'responds': False, 'english': False, 'accent': False, 'attitude': False, 'possibly': False, '_huge_': False, 'beside': False, 'includes': False, 'needlessly': False, 'stupid': False, 'jokes': False, 'olds': False, 'everyone': False, 'shakes': False, 'anyway': False, 'finds': False, 'usual': False, 'reaction': False, 'fluttered': False, 'paves': False, 'possible': False, 'pregnancy': False, 'birth': False, 'gag': False, 'book': False, 'friend': False, 'arnold': False, 'provides': False, 'cacophonous': False, 'funny': False, 'beats': False, 'costumed': False, 'arnie': False, 'dinosaur': False, 'draw': False, 'parallels': False, 'toy': False, 'store': False, 'jeff': False, 'goldblum': False, 'hid': False, 'dreadful': False, 'hideaway': False, 'artist': False, 'fear': False, 'simultaneous': False, 'longing': False, 'commitment': False, 'doctor': False, 'recently': False, 'switch': False, 'veterinary': False, 'medicine': False, 'obstetrics': False, 'joke': False, 'old': False, 'foreign': False, 'guy': False, 'mispronounces': False, 'stereotype': False, 'say': False, 'yakov': False, 'smirnov': False, 'favorite': False, 'vodka': False, 'hence': False, 'take': False, 'volvo': False, 'nasty': False, 'unamusing': False, 'heads': False, 'simultaneously': False, 'groan': False, 'failure': False, 'loud': False, 'failed': False, 'uninspired': False, 'lunacy': False, 'sunset': False, 'boulevard': False, 'arrest': False, 'please': False, 'caught': False, 'pants': False, 'bring': False, 'theaters': False, 'faces': False, '90': False, 'forced': False, 'unauthentic': False, 'anyone': False, 'q': False, '80': False, 'sorry': False, 'money': False, 'unfulfilled': False, 'desire': False, 'spend': False, 'bucks': False, 'call': False, 'road': False, 'trip': False, 'walking': False, 'wounded': False, 'stellan': False, 'skarsg': False, 'rd': False, 'convincingly': False, 'zombified': False, 'drunken': False, 'loser': False, 'difficult': False, 'smelly': False, 'boozed': False, 'reliable': False, 'swedish': False, 'adds': False, 'depth': False, 'significance': False, 'plodding': False, 'aberdeen': False, 'sentimental': False, 'painfully': False, 'mundane': False, 'european': False, 'playwright': False, 'august': False, 'strindberg': False, 'built': False, 'career': False, 'families': False, 'relationships': False, 'paralyzed': False, 'secrets': False, 'unable': False, 'express': False, 'longings': False, 'accurate': False, 'reflection': False, 'strives': False, 'focusing': False, 'pairing': False, 'alcoholic': False, 'tomas': False, 'alienated': False, 'openly': False, 'hostile': False, 'yuppie': False, 'kaisa': False, 'lena': False, 'headey': False, 'gossip': False, 'haven': False, 'spoken': False, 'wouldn': False, 'norway': False, 'scotland': False, 'automobile': False, 'charlotte': False, 'rampling': False, 'sand': False, 'rotting': False, 'hospital': False, 'bed': False, 'cancer': False, 'soap': False, 'opera': False, 'twist': False, 'days': False, 'live': False, 'blitzed': False, 'step': False, 'foot': False, 'plane': False, 'hits': False, 'open': False, 'loathing': False, 'each': False, 'periodic': False, 'stops': False, 'puke': False, 'dashboard': False, 'whenever': False, 'muttering': False, 'rotten': False, 'turned': False, 'sloshed': False, 'viewpoint': False, 'recognizes': False, 'apple': False, 'hasn': False, 'fallen': False, 'tree': False, 'nosebleeds': False, 'snorting': False, 'coke': False, 'sabotages': False, 'personal': False, 'indifference': False, 'restrain': False, 'vindictive': False, 'temper': False, 'ain': False, 'pair': False, 'true': False, 'notes': False, 'unspoken': False, 'familial': False, 'empathy': False, 'note': False, 'repetitively': False, 'bitchy': False, 'screenwriters': False, 'kristin': False, 'amundsen': False, 'hans': False, 'petter': False, 'moland': False, 'fabricate': False, 'series': False, 'contrivances': False, 'propel': False, 'forward': False, 'roving': False, 'hooligans': False, 'drunks': False, 'nosy': False, 'flat': False, 'tires': False, 'figure': False, 'schematic': False, 'convenient': False, 'narrative': False, 'reach': False, 'unveil': False, 'dark': False, 'past': False, 'simplistic': False, 'devices': False, 'trivialize': False, 'conflict': False, 'mainstays': False, 'wannabe': False, 'exists': False, 'purely': False, 'sake': False, 'weak': False, 'unimaginative': False, 'casting': False, 'thwarts': False, 'pivotal': False, 'role': False, 'were': False, 'stronger': False, 'actress': False, 'perhaps': False, 'coast': False, 'performances': False, 'moody': False, 'haunting': False, 'cinematography': False, 'rendering': False, 'pastoral': False, 'ghost': False, 'reference': False, 'certain': False, 'superior': False, 'indie': False, 'intentional': False, 'busy': False, 'using': False, 'furrowed': False, 'brow': False, 'convey': False, 'twitch': False, 'insouciance': False, 'paying': False, 'attention': False, 'maybe': False, 'doing': False, 'reveal': False, 'worthwhile': False, 'earlier': False, 'released': False, '2001': False, 'jonathan': False, 'nossiter': False, 'captivating': False, 'wonders': False, 'disturbed': False, 'parental': False, 'figures': False, 'bound': False, 'ceremonial': False, 'wedlock': False, 'differences': False, 'presented': False, 'significant': False, 'luminous': False, 'diva': False, 'preening': False, 'static': False, 'solid': False, 'performance': False, 'pathetic': False, 'drunk': False, 'emote': False, 'besides': False, 'catatonic': False, 'sorrow': False, 'genuine': False, 'ferocity': False, 'sexually': False, 'charged': False, 'frisson': False, 'during': False, 'understated': False, 'confrontations': False, 'suggest': False, 'gray': False, 'zone': False, 'complications': False, 'accompany': False, 'torn': False, 'romance': False, 'stifled': False, 'curiosity': False, 'thoroughly': False, 'explores': False, 'neurotic': False, 'territory': False, 'delving': False, 'americanization': False, 'greece': False, 'mysticism': False, 'illusion': False, 'deflect': False, 'pain': False, 'overloaded': False, 'willing': False, 'come': False, 'traditional': False, 'ambitious': False, 'sleepwalk': False, 'rhythms': False, 'timing': False, 'driven': False, 'stories': False, 'complexities': False, 'depressing': False, 'answer': False, 'lawrence': False, 'kasdan': False, 'trite': False, 'useful': False, 'grand': False, 'canyon': False, 'steve': False, 'martin': False, 'mogul': False, 'pronounces': False, 'riddles': False, 'answered': False, 'advice': False, 'heart': False, 'french': False, 'sees': False, 'parents': False, 'tim': False, 'roth': False, 'oops': False, 'vows': False, 'taught': False, 'musketeer': False, 'dude': False, 'used': False, 'fourteen': False, 'arrgh': False, 'swish': False, 'zzzzzzz': False, 'original': False, 'lacks': False, 'energy': False, 'next': False, 'hmmmm': False, 'justin': False, 'chambers': False, 'basically': False, 'uncharismatic': False, 'version': False, 'chris': False, 'o': False, 'donnell': False, 'range': False, 'mena': False, 'suvari': False, 'thora': False, 'birch': False, 'dungeons': False, 'dragons': False, 'miscast': False, 'deliveries': False, 'piss': False, 'poor': False, 'ms': False, 'fault': False, 'definitely': False, 'higher': False, 'semi': False, 'saving': False, 'grace': False, 'wise': False, 'irrepressible': False, 'once': False, 'thousand': False, 'god': False, 'beg': False, 'agent': False, 'marketplace': False, 'modern': False, 'day': False, 'roles': False, 'romantic': False, 'gunk': False, 'alright': False, 'yeah': False, 'yikes': False, 'notches': False, 'fellas': False, 'blares': False, 'ear': False, 'accentuate': False, 'annoy': False, 'important': False, 'behind': False, 'recognize': False, 'epic': False, 'fluffy': False, 'rehashed': False, 'cake': False, 'created': False, 'shrewd': False, 'advantage': False, 'kung': False, 'fu': False, 'phenomenon': False, 'test': False, 'dudes': False, 'keep': False, 'reading': False, 'editing': False, 'shoddy': False, 'banal': False, 'stilted': False, 'plentiful': False, 'top': False, 'horse': False, 'carriage': False, 'stand': False, 'opponent': False, 'scampering': False, 'cut': False, 'mouseketeer': False, 'rope': False, 'tower': False, 'jumping': False, 'chords': False, 'hanging': False, 'says': False, '14': False, 'shirt': False, 'strayed': False, 'championing': False, 'fun': False, 'stretches': False, 'atrocious': False, 'lake': False, 'reminded': False, 'school': False, 'cringe': False, 'musketeers': False, 'fat': False, 'raison': False, 'etre': False, 'numbers': False, 'hoping': False, 'packed': False, 'stuntwork': False, 'promoted': False, 'trailer': False, 'major': False, 'swashbuckling': False, 'beginning': False, 'finishes': False, 'juggling': False, 'ladders': False, 'ladder': False, 'definite': False, 'keeper': False, 'regurgitated': False, 'crap': False, 'tell': False, 'deneuve': False, 'placed': False, 'hullo': False, 'barely': False, 'ugh': False, 'small': False, 'annoyed': False, 'trash': False, 'gang': False, 'vow': False, 'stay': False, 'thank': False, 'outlaws': False, '5': False, 'crouching': False, 'tiger': False, 'hidden': False, 'matrix': False, 'replacement': False, 'killers': False, '6': False, 'romeo': False, 'die': False, 'shanghai': False, 'noon': False, 'remembered': False, 'dr': False, 'hannibal': False, 'lecter': False, 'michael': False, 'mann': False, 'forensics': False, 'thriller': False, 'manhunter': False, 'scottish': False, 'brian': False, 'cox': False, 'works': False, 'usually': False, 'schlock': False, 'halfway': False, 'goodnight': False, 'meaty': False, 'substantial': False, 'brilliant': False, 'check': False, 'dogged': False, 'inspector': False, 'opposite': False, 'frances': False, 'mcdormand': False, 'ken': False, 'loach': False, 'agenda': False, 'harrigan': False, 'disturbing': False, 'l': False, 'e': False, '47': False, 'picked': False, 'sundance': False, 'distributors': False, 'scared': False, 'budge': False, 'dares': False, 'speak': False, 'expresses': False, 'seeking': False, 'adolescents': False, 'pad': False, 'bothered': False, 'members': False, 'presentation': False, 'oddly': False, 'empathetic': False, 'light': False, 'tempered': False, 'robust': False, 'listens': False, 'opposed': False, 'friends': False, 'wire': False, 'act': False, 'confused': False, 'lives': False, 'pay': False, 'courtship': False, 'charming': False, 'temptations': False, 'grown': False, 'stands': False, 'island': False, 'expressway': False, 'slices': False, 'malls': False, 'class': False, 'homes': False, 'suburbia': False, 'filmmaker': False, 'cuesta': False, 'uses': False, 'transparent': False, 'metaphor': False, '15': False, 'protagonist': False, 'howie': False, 'franklin': False, 'dano': False, 'reveals': False, 'morbid': False, 'preoccupation': False, 'death': False, 'citing': False, 'deaths': False, 'alan': False, 'j': False, 'pakula': False, 'songwriter': False, 'harry': False, 'chapin': False, 'exit': False, '52': False, 'fascinated': False, 'feelings': False, 'projected': False, 'bright': False, 'move': False, 'force': False, 'complex': False, 'molesters': False, 'beast': False, 'ashamed': False, 'worked': False, 'ill': False, 'advised': False, 'foray': False, 'unnecessary': False, 'padding': False, 'miserable': False, 'bruce': False, 'altman': False, 'seat': False, 'collar': False, 'crime': False, 'degenerate': False, 'youngsters': False, 'kicks': False, 'robbing': False, 'houses': False, 'homoerotic': False, 'shenanigans': False, 'ass': False, 'terrio': False, 'billy': False, 'kay': False, 'handsome': False, 'artful': False, 'dodger': False, 'add': False, 'themes': False, 'suburban': False, 'ennui': False, 'needed': False, 'awkward': False, 'subplots': False, 'concurrently': False, 'relationship': False, 'evenly': False, 'paced': False, 'exceptionally': False, 'acted': False, 'sporting': False, 'baseball': False, 'cap': False, 'faded': False, 'marine': False, 'tattoo': False, 'bluff': False, 'bluster': False, 'quiet': False, 'glance': False, 'withdrawn': False, 'whose': False, 'dramatic': False, 'choices': False, 'broad': False, 'calling': False, 'haley': False, 'restraint': False, 'admirable': False, 'screenplay': False, 'material': False, 'reads': False, 'walt': False, 'whitman': False, 'poem': False, 'moment': False, 'precious': False, 'lingers': False, 'ecstatic': False, 'hearing': False, 'glenn': False, 'gould': False, 'performing': False, 'bach': False, 'goldberg': False, 'variations': False, 'involving': False, 'walter': False, 'masterson': False, 'jealous': False, 'newbie': False, 'thread': False, 'predictably': False, 'leads': False, 'observational': False, 'portrait': False, 'alienation': False, 'royally': False, 'screwed': False, 'terry': False, 'zwigoff': False, 'superb': False, 'confidence': False, 'ambivalent': False, 'typical': False, 'cinema': False, 'wrap': False, 'bullet': False, 'sparing': False, 'writers': False, 'philosophical': False, 'regard': False, 'countless': False, 'share': False, 'blockbuster': False, 'solved': False, 'obstacle': False, 'removed': False, 'often': False, 'extend': False, 'question': False, 'striving': False, 'realism': False, 'destroy': False, 'janeane': False, 'garofalo': False, 'couple': False, 'truth': False, 'cats': False, 'dogs': False, 'excruciating': False, 'matchmaker': False, 'books': False, 'plods': False, 'predestined': False, 'surprises': False, 'jumps': False, 'popular': False, 'political': False, 'satire': False, 'bandwagon': False, 'campaign': False, 'aide': False, 'massacusetts': False, 'senator': False, 'sanders': False, 'reelection': False, 'denis': False, 'leary': False, 'stereotypical': False, 'strategist': False, 'ethics': False, 'scandal': False, 'plagued': False, 'play': False, 'irish': False, 'roots': False, 'boston': False, 'roman': False, 'catholic': False, 'democrat': False, 'contingent': False, 'kennedy': False, 'family': False, 'orders': False, 'ireland': False, 'relatives': False, 'exploit': False, 'soon': False, 'learns': False, 'said': False, 'done': False, 'mantra': False, 'tiny': False, 'misses': False, 'bus': False, 'hotel': False, 'ends': False, 'smallest': False, 'trashiest': False, 'dog': False, 'luggage': False, 'roger': False, 'ebert': False, 'calls': False, 'meet': False, 'happens': False, 'unconventional': False, 'cinematic': False, 'walks': False, 'bathroom': False, 'nude': False, 'sean': False, 'david': False, 'hara': False, 'bathtub': False, 'points': False, 'guessing': False, 'water': False, 'hates': False, 'instant': False, 'saw': False, 'irishman': False, 'hate': False, 'awhile': False, 'succumb': False, 'charms': False, 'happily': False, 'superficial': False, 'detail': False, 'throw': False, 'turmoil': False, 'reconcile': False, 'tune': False, 'annual': False, 'matchmaking': False, 'festival': False, 'lonely': False, 'county': False, 'future': False, 'bliss': False, 'milo': False, 'shea': False, 'snyder': False, 'pops': False, 'onscreen': False, 'spew': False, 'souls': False, 'assured': False, 'match': False, 'utter': False, 'predictability': False, 'message': False, 'respectable': False, 'person': False, 'comedic': False, 'distinction': False, 'sell': False, 'script': False, 'excited': False, 'stays': False, 'stateside': False, 'yelling': False, 'phone': False, 'undoes': False, 'microphone': False, 'speech': False, 'known': False, 'flying': False, 'hong': False, 'kong': False, 'style': False, 'filmmaking': False, 'classics': False, 'nod': False, 'asia': False, 'france': False, 'lukewarm': False, 'dumas': False, 'asian': False, 'stunt': False, 'coordinator': False, 'xing': False, 'xiong': False, 'prior': False, 'attempts': False, 'choreography': False, 'laughable': False, 'van': False, 'damme': False, 'vehicle': False, 'team': False, 'dennis': False, 'rodman': False, 'simon': False, 'sez': False, 'thrown': False, 'air': False, 'result': False, 'tepid': False, 'adventure': False, 'rip': False, 'stinks': False, 'indiana': False, 'jones': False, 'simple': False, 'grandmother': False, 'adapted': False, 'artagnan': False, 'vengeful': False, 'son': False, 'slain': False, 'travels': False, 'paris': False, 'join': False, 'royal': False, 'meets': False, 'cunning': False, 'cardinal': False, 'richelieu': False, 'stephen': False, 'rea': False, 'overthrow': False, 'associate': False, 'febre': False, 'killer': False, 'disbanded': False, 'rounds': False, 'aramis': False, 'nick': False, 'moran': False, 'athos': False, 'jan': False, 'gregor': False, 'kremp': False, 'porthos': False, 'steven': False, 'spiers': False, 'wrongfully': False, 'imprisoned': False, 'leader': False, 'treville': False, 'prison': False, 'frisky': False, 'interest': False, 'chambermaid': False, 'francesca': False, 'footsy': False, 'coo': False, 'hunts': False, 'queen': False, 'captured': False, 'menancing': False, 'forcing': False, 'regroup': False, 'leading': False, 'charge': False, 'peter': False, 'hyams': False, 'wanted': False, 'blend': False, 'eastern': False, 'western': False, 'styles': False, 'disaster': False, 'reality': False, 'ones': False, 'jet': False, 'li': False, 'risk': False, 'ironically': False, 'swordplay': False, 'spread': False, 'carry': False, 'bulk': False, '30': False, 'minute': False, 'picture': False, 'weighs': False, 'monotonous': False, 'gene': False, 'quintano': False, 'prosaic': False, 'wedding': False, 'planner': False, 'mousy': False, 'artangnan': False, 'hyam': False, 'candles': False, 'torches': False, 'grime': False, 'filth': False, '17th': False, 'noted': False, 'standout': False, 'mortal': False, 'kombat': False, 'annihilation': False, 'reviewed': False, 'multiple': False, 'levels': False, 'rampant': False, 'usage': False, 'randian': False, 'subtext': False, 'pervades': False, 'occasionaly': False, 'ironic': False, 'depreciating': False, 'remark': False, 'tosses': False, 'clearly': False, 'marxist': False, 'imagery': False, 'kidding': False, 'seriousness': False, 'fair': False, '*': False, 'necessary': False, 'viewpoints': False, 'watcher': False, 'unfamiliar': False, 'marginally': False, 'fan': False, 'games': False, '1995': False, 'concerned': False, 'martial': False, 'arts': False, 'tournament': False, 'decide': False, 'fate': False, 'billion': False, 'inhabitants': False, 'mortals': False, 'theory': False, 'prevented': False, 'emperor': False, 'shao': False, 'khan': False, 'arriving': False, 'ready': False, 'assumed': False, 'stance': False, 'extraordinarily': False, 'myself': False, 'game': False, 'enjoyed': False, 'directors': False, 'knew': False, 'limitations': False, 'try': False, 'overachieve': False, 'accompanying': False, 'intersperesed': False, 'distracting': False, 'non': False, 'intrusive': False, 'bits': False, 'fluff': False, 'passing': False, 'smashing': False, 'success': False, 'box': False, 'office': False, 'picks': False, 'precisely': False, 'introductory': False, 'exposition': False, 'anyways': False, 'hell': False, 'silly': False, 'rule': False, 'winning': False, 'thereafter': False, 'approximately': False, '85': False, 'alternates': False, 'general': False, 'impression': False, 'producers': False, 'thought': False, 'formula': False, 'volumes': False, 'truly': False, 'sandra': False, 'hess': False, 'sonya': False, 'blade': False, 'execrable': False, 'convince': False, 'loved': False, 'johnny': False, 'greased': False, 'worst': False, 'mis': False, 'james': False, 'remar': False, 'raiden': False, 'thunder': False, 'christopher': False, 'lambert': False, 'japanese': False, 'revered': False, 'chinese': False, 'mystics': False, 'against': False, 'lister': False, 'jr': False, 'president': False, 'u': False, 'fifth': False, 'utility': False, 'totally': False, 'luxury': False, 'amused': False, 'awareness': False, 'introduced': False, 'meaningless': False, 'sidetracks': False, 'including': False, 'muddled': False, 'liu': False, 'kang': False, 'shou': False, 'seeks': False, 'nightwolf': False, 'litefoot': False, 'mystical': False, 'hallucination': False, 'jade': False, 'irina': False, 'pantaeva': False, 'reasons': False, 'unless': False, 'critiques': False, 'apply': False, 'worse': False, 'bridgette': False, 'convincing': False, 'looked': False, 'mimicing': False, 'movements': False, 'choreographer': False, 'knows': False, 'puts': False, 'believable': False, 'jax': False, 'earthquake': False, 'animality': False, 'bonus': False, 'similar': False, 'moves': False, 'mistakenly': False, 'hang': False, 'lamest': False, 'involved': False, 'mud': False, 'wrestling': False, 'lame': False, 'politically': False, 'incorrect': False, 'noticed': False, 'remarked': False, 'upon': False, 'emporer': False, 'perform': False, 'animalities': False, 'motaro': False, 'sheeva': False, 'lifelike': False, 'goro': False, 'enjoy': False, 'femme': False, 'la': False, 'nikita': False, 'backdraft': False, 'sliver': False, 'cindy': False, 'crawford': False, 'anne': False, 'parillaud': False, 'conspire': False, 'shattered': False, 'image': False, 'hooey': False, 'stallone': False, 'stone': False, 'specialist': False, 'poses': False, 'recurring': False, 'assassin': False, 'honeymooning': False, 'jamaica': False, 'believe': False, 'runs': False, 'painful': False, 'pedestrian': False, 'siouxsie': False, 'sioux': False, 'wig': False, 'emotionless': False, 'leather': False, 'clothing': False, 'seattle': False, 'moping': False, 'karen': False, 'endlessly': False, 'complicated': False, 'plots': False, 'helps': False, 'crisp': False, 'modicum': False, 'shakespearean': False, 'begin': False, 'saddled': False, 'leaden': False, 'zero': False, 'breaking': False, 'cardboard': False, 'confines': False, 'insist': False, 'couldn': False, 'huh': False, 'wonderful': False, 'interchange': False, 'charm': False, 'faster': False, 'learned': False, 'cereal': False, 'crybaby': False, 'imagines': False, 'stranger': False, 'sends': False, 'flowers': False, 'chromium': False, 'tough': False, 'nails': False, 'crack': False, 'killing': False, 'machine': False, 'shoots': False, 'mirrors': False, 'stock': False, 'interested': False, 'nest': False, 'egg': False, 'pave': False, 'paradise': False, 'put': False, 'parking': False, 'graham': False, 'greene': False, 'barbet': False, 'schroeder': False, 'reversal': False, 'fortune': False, 'co': False, 'produced': False, 'agonizingly': False, 'b': False, 'york': False, 'vampires': False, 'latest': False, 'opus': False, 'bent': False, 'outing': False, 'aptly': False, 'titled': False, 'suppose': False, 'went': False, 'prefixed': False, 'possessive': False, 'unashamed': False, 'punctuated': False, 'above': False, 'storyline': False, 'borders': False, 'idiotic': False, 'chaotic': False, 'dormant': False, 'martians': False, 'swirling': False, 'gases': False, 'awakened': False, 'meddling': False, 'possess': False, 'hapless': False, 'colonists': False, 'testy': False, 'marilyn': False, 'manson': False, 'lookalikes': False, 'pooh': False, 'bah': False, 'counsel': False, 'official': False, 'melanie': False, 'ballard': False, 'natasha': False, 'henstridge': False, 'sub': False, 'species': False, 'returnee': False, 'officer': False, 'incarcerated': False, 'felon': False, 'second': False, 'blonde': False, 'pulled': False, 'tightly': False, 'awkwardly': False, 'ponytail': False, 'ice': False, 'cube': False, 'appropriately': False, 'named': False, 'pam': False, 'grier': False, 'briefly': False, 'whom': False, 'wonder': False, 'host': False, 'extras': False, 'therefore': False, 'bird': False, 'shots': False, 'sprawling': False, 'metropolis': False, 'reddish': False, 'state': False, 'art': False, 'trademark': False, 'finding': False, 'department': False, 'lock': False, 'laughing': False, 'barrel': False, 'fare': False, 'dingy': False, 'interiors': False, 'cluttered': False, 'exteriors': False, 'inane': False, 'lots': False, 'scarred': False, 'crazed': False, 'aliens': False, 'weaponry': False, 'warfare': False, 'warning': False, 'spontaneously': False, 'stupidly': False, 'villains': False, 'border': False, 'conflicts': False, 'shootouts': False, 'minus': False, 'hissing': False, 'plissken': False, 'miss': False, 'dubbed': False, 'minimalist': False, 'soundtracks': False, 'graduated': False, 'effective': False, 'scoring': False, 'highlighting': False, 'screeching': False, 'guitar': False, 'fortunately': False, 'drowns': False, 'er': False, 'audible': False, 'priceless': False, 'proven': False, 'infertile': False, 'breeding': False, 'ground': False, 'stillborn': False, 'val': False, 'kilmer': False, 'disappointing': False, 'weekend': False, 'overshadowed': False, 'sequels': False, 'among': False, 'pie': False, 'rush': False, 'absent': False, 'references': False, 'set': False, 'perth': False, 'amboys': False, 'closest': False, 'neighbor': False, 'slap': False, 'upside': False, '1': False, 'keeps': False, 'miraculously': False, 'pretend': False, 'means': False, 'intelligent': False, 'grade': False, 'sci': False, 'fi': False, 'singularly': False, 'luck': False, 'starting': False, 'alicia': False, 'silverstone': False, 'beautiful': False, 'creatures': False, 'green': False, 'critic': False, 'large': False, 'choosing': False, 'strikes': False, 'crush': False, 'slow': False, 'moving': False, 'horrific': False, 'adaptation': False, 'clueless': False, 'mailed': False, 'saying': False, 'theater': False, 'expecting': False, 'preview': False, 'crazymadinlove': False, 'whiny': False, 'unlikable': False, 'wasn': False, 'yelled': False, 'f': False, '$&#': False, 'laugh': False, 'agreement': False, 'walked': False, 'babysitter': False, 'inner': False, 'compulsion': False, 'understand': False, 'rent': False, 'regret': False, 'paragraph': False, 'competition': False, 'criticizing': False, 'thin': False, 'shred': False, 'slower': False, 'glacier': False, 'writing': False, 'appeal': False, 'whatsoever': False, 'pointlessly': False, 'concluded': False, 'violent': False, 'plus': False, 'equals': False, 'spends': False, 'twenty': False, 'bubble': False, 'bath': False, 'joined': False, 'four': False, 'features': False, 'settle': False, 'friday': False, 'cocktail': False, 'automatically': False, 'nights': False, 'trods': False, 'discover': False, 'silent': False, 'object': False, 'male': False, 'fantasies': False, 'thinks': False, 'recapture': False, 'youth': False, 'boyfriend': False, 'lets': False, 'wild': False, 'spying': False, 'outside': False, 'prepubescent': False, 'keyhole': False, 'aged': False, 'counterpart': False, 'asked': False, '200': False, 'pound': False, 'silk': False, 'teddy': False, 'fanatasies': False, 'realm': False, 'pg': False, 'imagine': False, 'cinemax': False, 'staple': False, 'absolutely': False, 'pointed': False, 'classify': False, 'mix': False, 'various': False, 'encounters': False, 'third': False, 'space': False, 'odyssey': False, 'apollo': False, 'contact': False, 'hope': False, 'melange': False, 'considering': False, 'disastrous': False, 'results': False, 'sucks': False, 'rescue': False, 'astronauts': False, 'sent': False, '2020': False, 'unknown': False, 'aviators': False, 'visit': False, 'underwhelming': False, 'describe': False, 'uneven': False, 'promise': False, 'buzz': False, 'neutral': False, 'cherry': False, 'colored': False, 'nerdies': False, 'techie': False}\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import random\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "nltk.download('movie_reviews')\n",
        "docs = [(list(movie_reviews.words(fileid)),category)\n",
        "  for category in movie_reviews.categories()\n",
        "  for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "random.shuffle(docs)\n",
        "\n",
        "print(docs[1])\n",
        "\n",
        "all=[]\n",
        "for w in movie_reviews.words():\n",
        "  all.append(w.lower())\n",
        "\n",
        "all=nltk.FreqDist(all)\n",
        "word_features=list(all.keys())[:3000]\n",
        "\n",
        "\n",
        "##Notice that we have introduced a new variable with the name word_features. \n",
        "##This variable will hold the most popular 3000 words. \n",
        "##We now need to create a function that will help us find these words from \n",
        "##both the positive and negative documents, with their presence being marked as either \n",
        "##positive or negative. Here is the function:\n",
        "\n",
        "\n",
        "def search_features(doc):\n",
        "  words=set(doc)\n",
        "  features={}\n",
        "  for w in word_features:\n",
        "    features[w]=(w in words)\n",
        "\n",
        "  return features\n",
        "\n",
        "print(search_features(movie_reviews.words('neg/cv000_29416.txt')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT0uMKjprFsQ"
      },
      "source": [
        "# Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWqsLs8WrJsw",
        "outputId": "6c444283-ca0d-4a58-d537-79586105add8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['one', 'of', 'these', 'days', ',', 'i', \"'\", 'll', 'make', 'good', 'on', 'my', 'promise', 'never', 'to', 'rent', 'another', 'abel', 'ferrara', 'movie', '.', 'king', 'of', 'new', 'york', 'and', 'body', 'snatchers', 'notwithstanding', '(', 'and', 'bad', 'lieutenant', 'is', 'only', 'fit', 'for', 'a', 'single', ',', 'emotive', 'viewing', ')', ',', 'his', 'exploitation', 'flicks', 'have', 'fallen', 'into', 'a', 'rut', 'of', 'hoary', 'art', '-', 'house', 'trappings', '.', 'it', \"'\", 's', 'a', 'perfume', '-', 'drenched', ',', 'coke', '-', 'addled', 'visit', 'to', 'the', 'seedy', 'pornography', 'shop', ',', 'where', 'beautiful', 'models', '(', 'no', ',', 'hookers', '--', 'no', ',', 'courtesans', ')', 'usher', 'you', 'through', 'the', 'silk', 'curtains', '.', 'ferrara', \"'\", 's', 'only', 'consistently', 'smart', 'move', 'has', 'been', 'casting', 'christopher', 'walken', 'over', 'and', 'over', 'again', ',', 'since', 'walken', 'can', 'make', 'a', 'good', 'movie', 'great', 'and', 'a', 'loathsome', 'movie', 'durable', 'whenever', 'he', \"'\", 's', 'onscreen', '.', 'his', '8', '-', 'minute', 'scene', 'in', 'the', 'addiction', 'is', 'the', 'saving', 'grace', 'of', 'that', 'otherwise', 'abysmal', ',', 'unwatchable', ',', 'and', 'pretentious', 'failure', '.', 'when', 'he', 'starts', 'talking', 'about', 'his', 'vampiric', 'bowel', 'movements', ',', 'or', 'questions', 'whether', 'lili', 'taylor', 'has', 'ever', 'read', 'naked', 'lunch', ',', 'there', \"'\", 's', 'a', 'much', '-', 'needed', 'dose', 'of', 'humor', 'in', 'an', 'otherwise', 'terminally', 'unfunny', 'affair', '.', 'you', 'know', 'those', 'gothic', 'club', 'kids', 'who', 'are', 'too', 'cool', 'to', 'smile', 'and', 'let', 'you', 'know', 'they', \"'\", 're', 'actually', 'having', 'fun', '?', 'the', 'addiction', 'is', 'that', 'movie', '.', 'walken', ',', 'sadly', ',', 'does', 'not', 'appear', 'in', 'the', 'blackout', '.', 'the', 'central', 'role', 'of', 'matty', ',', 'a', 'junkie', 'film', 'star', 'whose', 'lightning', 'paced', 'hollywood', 'life', 'among', 'the', 'beautiful', 'people', 'is', 'inevitably', 'leading', 'to', 'his', 'destruction', ',', 'is', 'played', 'by', 'matthew', 'modine', '(', 'who', 'takes', 'what', 'he', 'can', 'get', 'after', 'cutthroat', 'island', ')', '.', 'much', 'like', 'the', 'protagonists', 'of', 'michelangelo', 'antonioni', \"'\", 's', 'terminally', 'bored', 'cultural', 'elite', ',', 'matty', 'is', 'involved', 'in', 'a', 'bitter', 'pill', '\"', 'relationship', '\"', 'with', 'high', 'fashioned', 'model', 'annie', '(', 'at', 'least', 'i', 'think', 'she', \"'\", 's', 'a', 'model', '.', ')', 'matty', \"'\", 's', 'lady', 'is', 'played', 'by', 'french', 'actress', 'b', '?', 'atrice', 'dalle', ',', 'arrested', 'twice', 'for', 'cocaine', 'possession', 'during', 'filming', 'of', 'the', 'blackout', '--', 'not', 'that', 'you', 'needed', 'to', 'know', 'that', ',', 'but', 'it', 'lends', 'credence', 'to', 'the', 'idea', 'that', 'ferrara', \"'\", 's', 'entire', 'oeuvre', 'has', 'been', 'filmed', 'in', 'a', 'fucking', 'blackout', '.', 'no', 'kidding', '.', 'requiem', 'for', 'a', 'dream', 'has', 'nothing', 'on', 'the', 'junkie', 'presentations', 'seen', 'in', 'ferrara', \"'\", 's', 'movies', 'and', 'his', 'controversial', 'urban', 'lifestyle', '.', 'matty', 'and', 'annie', 'struggle', 'over', 'her', 'decision', 'to', 'have', 'an', 'abortion', 'without', 'consulting', 'him', '.', 'no', 'doubt', ',', 'he', 'was', 'off', 'chasing', 'the', 'dragon', '.', 'in', 'his', 'despair', ',', 'matty', 'indulges', 'in', 'a', 'chemical', 'induced', 'weekend', 'of', 'debauchery', ',', 'tooling', 'around', 'the', 'streets', 'of', 'miami', 'with', 'video', 'filmmaker', 'mickey', 'wayne', '(', 'dennis', 'hopper', ',', 'in', 'full', '\"', 'dirty', 'ol', \"'\", 'man', '\"', 'mold', 'smacking', 'models', 'on', 'the', 'ass', 'and', 'telling', 'them', 'to', 'spread', 'their', 'legs', '.', 'wider', '!', ')', 'toward', 'the', 'end', 'of', 'the', 'night', ',', 'they', 'pick', 'up', 'a', 'teenage', 'waitress', 'also', 'named', 'annie', '(', 'sarah', 'lassez', ')', ',', 'start', 'shooting', 'a', 'hastily', 'improvised', 'sexual', 'scene', ',', 'then', 'matty', 'thankfully', 'blacks', 'out', '.', 'something', 'happened', 'that', 'night', 'which', 'haunts', 'him', 'throughout', 'the', 'rest', 'of', 'the', 'movie', ',', 'and', 'it', \"'\", 's', 'exactly', 'what', 'you', 'think', 'it', 'was', '.', 'suffice', 'to', 'say', ',', 'there', \"'\", 's', 'some', 'confusion', 'over', 'whether', 'he', 'killed', 'annie', 'one', 'or', 'annie', 'two', ',', 'or', 'anyone', 'at', 'all', '.', 'the', 'blackout', 'is', 'typical', 'ferrara', ':', 'no', 'plot', 'to', 'speak', 'of', ',', 'plenty', 'of', 'raunch', ',', 'and', 'horribly', 'vogue', 'images', 'of', 'matthew', 'modine', 'downing', 'a', 'bottle', 'of', 'jack', 'daniels', 'and', 'a', 'beer', 'while', 'wrapping', 'himself', 'in', 'a', 'see', '-', 'through', 'curtain', 'in', 'his', 'hotel', 'room', 'by', 'the', 'sea', ',', 'by', 'the', 'sea', ',', 'by', 'the', 'beautiful', 'sea', '.', 'cinematographer', 'ken', 'kelsch', 'finds', 'inconsistent', 'glory', 'in', 'alternating', 'gorgeous', 'painterly', 'sunsets', 'with', 'docu', '-', 'style', 'sleaze', '(', 'and', 'we', \"'\", 're', 'back', 'to', 'dennis', 'hopper', 'leering', 'at', 'girls', 'in', 'bathing', 'suits', '.', '\"', 'yeah', '!', '!', '!', 'yeah', '!', '!', '!', 'arrrghhh', '!', '\"', 'says', 'mr', '.', 'hopper', '.', 'dirty', 'old', 'sod', '.', ')', 'it', \"'\", 's', 'compulsive', 'viewing', 'in', 'a', 'tacky', 'sort', 'of', 'way', ',', 'leading', 'to', 'a', 'ridiculous', 'climax', 'where', 'modine', 'seizes', 'control', 'of', 'his', 'destiny', '.', 'how', \"'\", 's', 'that', 'for', 'cryptic', '?', 'never', 'fear', '--', 'ferrara', 'finds', 'time', 'for', 'some', 'female', 'full', 'frontal', 'nudity', 'to', 'remind', 'us', 'what', 'he', \"'\", 's', 'all', 'about', '.', 'i', 'can', 'picture', 'it', 'now', '.', '\"', 'take', 'off', 'yer', 'clothes', ',', 'kid', '--', 'it', \"'\", 's', 'essential', 'to', 'depict', 'the', 'inner', 'maelstrom', 'of', 'my', 'central', 'protagonist', ',', 'and', 'you', \"'\", 're', 'his', 'visual', 'id', '.', 'you', \"'\", 're', 'the', 'soul', ',', 'the', 'heart', ',', 'the', 'bloodstream', 'of', 'the', 'picture', '.', 'take', 'it', 'off', '!', 'take', 'it', 'all', 'off', '!', '!', '!', 'ha', 'ha', 'ha', '!', '\"', 'friggin', \"'\", 'vampire', '.', 'yeah', ',', 'you', ',', 'ferrara', '.', 'a', 'final', 'word', 'about', 'matthew', 'modine', ':', 'he', \"'\", 's', 'actually', 'a', 'fine', 'actor', 'when', 'properly', 'cast', ',', 'but', 'there', \"'\", 's', 'something', 'too', 'squeaky', '-', 'clean', 'in', 'his', 'demeanor', '.', 'he', \"'\", 's', 'ideally', 'suited', 'for', 'sarcastic', 'men', 'in', 'tightly', 'controlled', 'situations', ',', 'such', 'as', 'his', 'private', 'joker', 'in', 'full', 'metal', 'jacket', 'or', 'the', 'time', '-', 'bomb', 'nebbish', 'in', 'short', 'cuts', '(', 'who', 'is', 'every', 'bit', 'as', 'superb', 'as', 'julianne', 'moore', 'in', 'that', 'famous', 'scene', ',', 'though', 'no', 'one', 'seems', 'to', 'notice', 'him', ')', '.', '[', 'he', 'was', 'in', 'that', 'scene', '?', '-', 'ed', '.', ']', 'here', ',', 'he', \"'\", 's', 'asked', 'to', 'let', 'it', 'all', 'hang', 'out', ',', 'sporting', 'a', 'three', '-', 'day', 'stubble', 'and', 'oily', 'bangs', '.', 'he', 'throws', 'around', 'furniture', 'like', 'stanley', 'kowalski', ',', 'but', 'it', \"'\", 's', 'somehow', 'lacking', '.', 'modine', 'lacks', 'the', 'feral', 'intensity', 'of', 'brando', ',', 'entirely', 'miscast', 'in', 'ferrara', \"'\", 's', 'flesh', 'fair', '.', 'better', 'luck', 'next', 'time', ',', 'matt', '.', 'someday', ',', 'you', \"'\", 'll', 'be', 'forgiven', 'for', 'cutthroat', 'island', ',', 'which', 'wasn', \"'\", 't', 'really', 'your', 'fault', 'in', 'the', 'first', 'place', '.', 'maybe', 'atom', 'egoyan', 'will', 'find', 'a', 'place', 'for', 'you', 'somewhere', ',', 'and', 'all', 'will', 'once', 'again', 'be', 'well', 'in', 'your', 'world', '.'], 'neg')\n",
            "Classifier accuracy percentage: 79.0\n",
            "Most Informative Features\n",
            "                   sucks = True              neg : pos    =     10.2 : 1.0\n",
            "                  annual = True              pos : neg    =      9.3 : 1.0\n",
            "                  turkey = True              neg : pos    =      8.1 : 1.0\n",
            "           unimaginative = True              neg : pos    =      8.1 : 1.0\n",
            "             silverstone = True              neg : pos    =      7.4 : 1.0\n",
            "                 frances = True              pos : neg    =      7.2 : 1.0\n",
            "                  regard = True              pos : neg    =      7.2 : 1.0\n",
            "              schumacher = True              neg : pos    =      7.2 : 1.0\n",
            "                 idiotic = True              neg : pos    =      6.8 : 1.0\n",
            "                obstacle = True              pos : neg    =      6.6 : 1.0\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import random\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "nltk.download('movie_reviews')\n",
        "docs = [(list(movie_reviews.words(fileid)), category)\n",
        "        for category in movie_reviews.categories()\n",
        "        for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "random.shuffle(docs)\n",
        "\n",
        "print(docs[1])\n",
        "\n",
        "all_words = []\n",
        "for w in movie_reviews.words():\n",
        "    all_words.append(w.lower())\n",
        "\n",
        "all_words = nltk.FreqDist(all_words)\n",
        "word_features = list(all_words.keys())[:3000]\n",
        "\n",
        "def search_features(doc):\n",
        "    words = set(doc)\n",
        "    features = {}\n",
        "    for w in word_features:\n",
        "        features[w] = (w in words)\n",
        "    return features\n",
        "\n",
        "featuresets = [(search_features(doc), category) for (doc, category) in docs]\n",
        "\n",
        "testing_set = featuresets[1900:]\n",
        "training_set = featuresets[:1900]\n",
        "\n",
        "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
        "\n",
        "print(\"Classifier accuracy percentage:\", (nltk.classify.accuracy(classifier, testing_set)) * 100)\n",
        "\n",
        "classifier.show_most_informative_features(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSKbURahHm1e"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66ftjC-gGihF",
        "outputId": "3455f1f8-0760-4e10-b9ca-2c747ff0338c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from Textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EPxcnDaGnWX",
        "outputId": "fd210d2c-d349-47e1-db38-e807365a3bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2022.12.7)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EIwuvHeMGwfh"
      },
      "outputs": [],
      "source": [
        " from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        " analyser=SentimentIntensityAnalyzer()\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgUeBDejHmYo",
        "outputId": "099be980-46e8-45cc-abaa-93f0e7b0f809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The car is cool!------------------------{'neg': 0.0, 'neu': 0.536, 'pos': 0.464, 'compound': 0.3802}\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "def sentiment_analyzer_scores(sentence):\n",
        "  score=analyser.polarity_scores(sentence)\n",
        "  print(\"{:-<40}{}\".format(sentence,str(score)))\n",
        "\n",
        "print(sentiment_analyzer_scores(\"The car is cool!\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfJd5r-yXy9q",
        "outputId": "1f928ab3-e9ac-49ec-a531-231b06c1ef6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The car is cool-------------------------{'neg': 0.0, 'neu': 0.566, 'pos': 0.434, 'compound': 0.3182}\n",
            "None\n",
            "The car is cool!------------------------{'neg': 0.0, 'neu': 0.536, 'pos': 0.464, 'compound': 0.3802}\n",
            "None\n",
            "The car is cool!!-----------------------{'neg': 0.0, 'neu': 0.51, 'pos': 0.49, 'compound': 0.4374}\n",
            "None\n",
            "The car is cool!!!----------------------{'neg': 0.0, 'neu': 0.486, 'pos': 0.514, 'compound': 0.4898}\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_analyzer_scores(\"The car is cool\"))\n",
        "print(sentiment_analyzer_scores(\"The car is cool!\"))\n",
        "print(sentiment_analyzer_scores(\"The car is cool!!\"))\n",
        "print(sentiment_analyzer_scores(\"The car is cool!!!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWvNdY09dRqz",
        "outputId": "c92ce816-9f04-4f99-e341-fad0265af6ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The car is cool!------------------------{'neg': 0.0, 'neu': 0.536, 'pos': 0.464, 'compound': 0.3802}\n",
            "None\n",
            "The car is marginally cool!-------------{'neg': 0.0, 'neu': 0.635, 'pos': 0.365, 'compound': 0.318}\n",
            "None\n",
            "The car is extremely cool!--------------{'neg': 0.0, 'neu': 0.581, 'pos': 0.419, 'compound': 0.4376}\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_analyzer_scores(\"The car is cool!\"))\n",
        "print(sentiment_analyzer_scores(\"The car is marginally cool!\"))\n",
        "print(sentiment_analyzer_scores(\"The car is extremely cool!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGXLWcGGbF8t",
        "outputId": "a39b61d6-faf6-45b6-d50c-fbbbeff56666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I enjoyed your hotel food, but I didn't like the way waiters offer their services{'neg': 0.15, 'neu': 0.73, 'pos': 0.121, 'compound': -0.1318}\n",
            "None\n"
          ]
        }
      ],
      "source": [
        " from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        " analyser=SentimentIntensityAnalyzer()\n",
        "\n",
        " def sentiment_analyzer_scores(sentence):\n",
        "  score=analyser.polarity_scores(sentence)\n",
        "  print(\"{:-<40}{}\".format(sentence,str(score)))\n",
        "\n",
        "print(sentiment_analyzer_scores(\"I enjoyed your hotel food, but I didn't like the way waiters offer their services\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh8ZcdmLwp97"
      },
      "source": [
        "# Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIgzkA2wws29",
        "outputId": "b80500ea-485a-47aa-d3fb-93439989bd01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chatterbot\n",
            "  Downloading ChatterBot-1.0.5-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from chatterbot) (2022.7.1)\n",
            "Collecting python-dateutil<2.8,>=2.7\n",
            "  Downloading python_dateutil-2.7.5-py2.py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m225.7/225.7 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pint>=0.8.1\n",
            "  Downloading Pint-0.20.1-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m269.5/269.5 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy<2.2,>=2.1\n",
            "  Downloading spacy-2.1.9.tar.gz (30.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyyaml<5.2,>=5.1\n",
            "  Downloading PyYAML-5.1.2.tar.gz (265 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m265.0/265.0 KB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mathparse<0.2,>=0.1\n",
            "  Downloading mathparse-0.1.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: nltk<4.0,>=3.2 in /usr/local/lib/python3.8/dist-packages (from chatterbot) (3.7)\n",
            "Collecting sqlalchemy<1.3,>=1.2\n",
            "  Downloading SQLAlchemy-1.2.19.tar.gz (5.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymongo<4.0,>=3.3\n",
            "  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m526.2/526.2 KB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk<4.0,>=3.2->chatterbot) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk<4.0,>=3.2->chatterbot) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk<4.0,>=3.2->chatterbot) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk<4.0,>=3.2->chatterbot) (2022.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<2.8,>=2.7->chatterbot) (1.15.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.2,>=2.1->chatterbot) (2.25.1)\n",
            "Collecting plac<1.0.0,>=0.9.6\n",
            "  Using cached plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.2,>=2.1->chatterbot) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.2,>=2.1->chatterbot) (1.0.9)\n",
            "Collecting thinc<7.1.0,>=7.0.8\n",
            "  Using cached thinc-7.0.8-cp38-cp38-linux_x86_64.whl\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "  Using cached preshed-2.0.1-cp38-cp38-linux_x86_64.whl\n",
            "Collecting srsly<1.1.0,>=0.0.6\n",
            "  Using cached srsly-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.2,>=2.1->chatterbot) (2.0.7)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "  Using cached blis-0.2.4-cp38-cp38-linux_x86_64.whl\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.2,>=2.1->chatterbot) (0.10.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (2.10)\n",
            "Building wheels for collected packages: pyyaml, spacy, sqlalchemy\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp38-cp38-linux_x86_64.whl size=44117 sha256=d3f5d19b373f4eb011e4397306957d67386ec014feab9c1d7244cb5141c7b6e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/40/9f/027c3d94280ce2b7c2c107cb563a433e6572f830a5462231ae\n",
            "  Building wheel for spacy (pyproject.toml) ... \u001b[?25l\u001b[?25hcanceled\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chatterbot_corpus\n",
            "  Downloading chatterbot_corpus-1.2.0-py2.py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m117.3/117.3 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML<4.0,>=3.12\n",
            "  Downloading PyYAML-3.13.tar.gz (270 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m270.6/270.6 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-3.13-cp38-cp38-linux_x86_64.whl size=43098 sha256=6ea9a99d44131cafe42bd6b3f327cf16c16186183457258d661e96e4362ae3e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/f2/07/5e58b12bc11255c3fc0a0aca89849050a8ec203d8b4a3c52c0\n",
            "Successfully built PyYAML\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 167, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py\", line 397, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py\", line 529, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 202, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3033, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in parse_requirements\n",
            "    yield Requirement(line)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3101, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 1124, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 3863, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 4091, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 3863, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 4936, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 3863, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 3863, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 5203, in parseImpl\n",
            "    return super().parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 4352, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 3841, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 4091, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 4352, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 3841, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 4091, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 810, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 4091, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 804, in _parseNoCache\n",
            "    pre_loc = self.preParse(instring, loc)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing/core.py\", line 757, in preParse\n",
            "    while loc < instrlen and instring[loc] in white_chars:\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 221, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 205, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1434, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.8/logging/handlers.py\", line 71, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1187, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 929, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 110, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 676, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 626, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 103, in print_exception\n",
            "    for line in TracebackException(\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 493, in __init__\n",
            "    context = TracebackException(\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 503, in __init__\n",
            "    self.__cause__ = cause\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install chatterbot\n",
        "!pip install chatterbot_corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0tszLJ5xUoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83344059-591b-405f-d93b-801b579a2533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chatterbot_corpus\n",
            "  Using cached chatterbot_corpus-1.2.0-py2.py3-none-any.whl (117 kB)\n",
            "Collecting PyYAML<4.0,>=3.12\n",
            "  Using cached PyYAML-3.13-cp38-cp38-linux_x86_64.whl\n",
            "Installing collected packages: PyYAML, chatterbot_corpus\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2022.2.1 requires pyyaml>=5.3.1, but you have pyyaml 3.13 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-3.13 chatterbot_corpus-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chatterbot\n",
            "  Using cached ChatterBot-1.0.5-py2.py3-none-any.whl (67 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from chatterbot) (2022.7.1)\n",
            "Collecting sqlalchemy<1.3,>=1.2\n",
            "  Using cached SQLAlchemy-1.2.19.tar.gz (5.7 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spacy<2.2,>=2.1\n",
            "  Using cached spacy-2.1.9.tar.gz (30.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dateutil<2.8,>=2.7\n",
            "  Using cached python_dateutil-2.7.5-py2.py3-none-any.whl (225 kB)\n",
            "Collecting pint>=0.8.1\n",
            "  Using cached Pint-0.20.1-py3-none-any.whl (269 kB)\n",
            "Requirement already satisfied: nltk<4.0,>=3.2 in /usr/local/lib/python3.8/dist-packages (from chatterbot) (3.7)\n",
            "Collecting pymongo<4.0,>=3.3\n",
            "  Using cached pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "Collecting mathparse<0.2,>=0.1\n",
            "  Using cached mathparse-0.1.2-py3-none-any.whl (7.2 kB)\n",
            "Collecting pyyaml<5.2,>=5.1\n",
            "  Using cached PyYAML-5.1.2-cp38-cp38-linux_x86_64.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk<4.0,>=3.2->chatterbot) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk<4.0,>=3.2->chatterbot) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk<4.0,>=3.2->chatterbot) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk<4.0,>=3.2->chatterbot) (2022.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<2.8,>=2.7->chatterbot) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.2,>=2.1->chatterbot) (1.21.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.2,>=2.1->chatterbot) (0.10.1)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "  Using cached blis-0.2.4-cp38-cp38-linux_x86_64.whl\n",
            "Collecting plac<1.0.0,>=0.9.6\n",
            "  Using cached plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Collecting srsly<1.1.0,>=0.0.6\n",
            "  Using cached srsly-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "  Using cached preshed-2.0.1-cp38-cp38-linux_x86_64.whl\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.2,>=2.1->chatterbot) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.2,>=2.1->chatterbot) (1.0.9)\n",
            "Collecting thinc<7.1.0,>=7.0.8\n",
            "  Using cached thinc-7.0.8-cp38-cp38-linux_x86_64.whl\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.2,>=2.1->chatterbot) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (1.24.3)\n",
            "Building wheels for collected packages: spacy, sqlalchemy\n",
            "  Building wheel for spacy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy: filename=spacy-2.1.9-cp38-cp38-linux_x86_64.whl size=49694617 sha256=4b08b59607c5f7545c2f08c8aa878c6cf344bb231c27e3fcd6c60df41e68ce6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/c2/73/989e659e83b30a74acdfcb825e632b1a7dc12f39d58fe37dd6\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.2.19-cp38-cp38-linux_x86_64.whl size=1160242 sha256=2509a3a478db2c86d066feb3e312b77cdb4c323505e381c5f30e7c61e40bdc75\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/13/f8/47c2f3157957c3693caffa64a94a718cb1357fe186e4d52e48\n",
            "Successfully built spacy sqlalchemy\n",
            "Installing collected packages: sqlalchemy, plac, mathparse, srsly, pyyaml, python-dateutil, pymongo, preshed, pint, blis, thinc, spacy, chatterbot\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.46\n",
            "    Uninstalling SQLAlchemy-1.4.46:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.46\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.5\n",
            "    Uninstalling srsly-2.4.5:\n",
            "      Successfully uninstalled srsly-2.4.5\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.3\n",
            "    Uninstalling pymongo-4.3.3:\n",
            "      Successfully uninstalled pymongo-4.3.3\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.8\n",
            "    Uninstalling preshed-3.0.8:\n",
            "      Successfully uninstalled preshed-3.0.8\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.9\n",
            "    Uninstalling blis-0.7.9:\n",
            "      Successfully uninstalled blis-0.7.9\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.7\n",
            "    Uninstalling thinc-8.1.7:\n",
            "      Successfully uninstalled thinc-8.1.7\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.4\n",
            "    Uninstalling spacy-3.4.4:\n",
            "      Successfully uninstalled spacy-3.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "prophet 1.1.2 requires python-dateutil>=2.8.0, but you have python-dateutil 2.7.5 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.1.9 which is incompatible.\n",
            "dask 2022.2.1 requires pyyaml>=5.3.1, but you have pyyaml 5.1.2 which is incompatible.\n",
            "confection 0.0.4 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.6 which is incompatible.\n",
            "chatterbot-corpus 1.2.0 requires PyYAML<4.0,>=3.12, but you have pyyaml 5.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-0.2.4 chatterbot-1.0.5 mathparse-0.1.2 pint-0.20.1 plac-0.9.6 preshed-2.0.1 pymongo-3.13.0 python-dateutil-2.7.5 pyyaml-5.1.2 spacy-2.1.9 sqlalchemy-1.2.19 srsly-1.0.6 thinc-7.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade chatterbot_corpus\n",
        "!pip install --upgrade chatterbot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fr55-_6xsRD"
      },
      "outputs": [],
      "source": [
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ListTrainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DihxLCLKx3DG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1631e8-3b39-4730-ae01-983653d92a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "my_bot=ChatBot(name='PyBot', read_only=True, logic_adapters=['chatterbot.logic.MathematicalEvaluation', 'chatterbot.logic.BestMatch'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k05C2XEcZYvq"
      },
      "outputs": [],
      "source": [
        "small_talk=['hi there!',\n",
        "            'hi!',\n",
        "            'how do you do?',\n",
        "            'how are you?',\n",
        "            'i\\'m cool.',\n",
        "            'fine, you?',\n",
        "            'always cool.',\n",
        "            'i\\'m ok',\n",
        "            'glad to hear that.',\n",
        "            'i\\'m fine',\n",
        "            'glad to hear that.',\n",
        "            'i feel awesome',\n",
        "            'excellent, glad to hear that.',\n",
        "            'not so good',\n",
        "            'sorry to hear that.',\n",
        "            'what\\'s your name?',\n",
        "            'i\\'m pybot. ask me a math question, please.']\n",
        "\n",
        "math_talk_2=['law of cosines',\n",
        "             'c**2 = a**2 + b**2-2*a*b*cos(gamma)']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyFqGZOTc1AT"
      },
      "outputs": [],
      "source": [
        "list_trainer=ListTrainer(my_bot)\n",
        "\n",
        "for item in (small_talk, math_talk_2):\n",
        "    list_trainer.train(item)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzFhXAXldGqy"
      },
      "outputs": [],
      "source": [
        "print(my_bot.get_response(\"hi\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_bot.get_response(\"where are you going?\"))"
      ],
      "metadata": {
        "id": "OnvWsU-YzYqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_bot.get_response(\"what is todays date?\"))"
      ],
      "metadata": {
        "id": "3qSmbsHEzZYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_bot.get_response(\"hello, how are you doing today\"))"
      ],
      "metadata": {
        "id": "K20fo-4hzcdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8nbSVoBejVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc37db80-7256-46f1-c905-d5d9b390a5af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/chatterbot/corpus.py:38: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  return yaml.load(data_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i feel awesome today\n"
          ]
        }
      ],
      "source": [
        "print(my_bot.get_response(\"i feel awesome today\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPjXXe3KewCk"
      },
      "outputs": [],
      "source": [
        "print(my_bot.get_response(\"what's your name?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4Rb4xOqthED"
      },
      "outputs": [],
      "source": [
        "print(my_bot.get_response(\"do you know the law of cosines?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4muazwRFxly"
      },
      "outputs": [],
      "source": [
        "print(my_bot.get_response(\"always cool.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2S5q7Pkt7MN"
      },
      "outputs": [],
      "source": [
        "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
        "\n",
        "corpus_trainer=ChatterBotCorpusTrainer(my_bot)\n",
        "corpus_trainer.train('chatterbot.corpus.english')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV-XGq_ZMNAT"
      },
      "source": [
        "# WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XluGLSnpMQSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ece20d4-0984-46bb-fd9d-751edfde3068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.8/dist-packages (1.8.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from wordcloud) (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from wordcloud) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.8/dist-packages (from wordcloud) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (2.7.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm9naKuCNCtI"
      },
      "outputs": [],
      "source": [
        "from io import IncrementalNewlineDecoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkQgYeEqNvUR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "2de84edd-1e9a-4325-ece9-2c1abf670ccf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e78007b0e842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load in the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Highway-Rail_Grade_Crossing_Accident_Data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Highway-Rail_Grade_Crossing_Accident_Data.csv'"
          ]
        }
      ],
      "source": [
        "#Load in the dataframe\n",
        "df=pd.read_csv(\"/content/Highway-Rail_Grade_Crossing_Accident_Data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01fIRbNmOVu6"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_grICtN9O5W1"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE_bUpdzPD0S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "0abf6084-31ab-4244-e72a-be4ab824c6f5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5f16ad96fb53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Weather Condition\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"City Name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Highway Name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df[[\"Weather Condition\", \"City Name\", \"Highway Name\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TooYuFvJParh"
      },
      "outputs": [],
      "source": [
        "CityName=df.groupby(\"City Name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gsbOFhXPf39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "97bc7358-8763-4d3d-e35d-76a1cb2be6aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Year                                                              \\\n",
              "            count    mean       std     min      25%     50%      75%     max   \n",
              "County                                                                          \n",
              "Albany       32.0  2005.5  9.380832  1990.0  1997.75  2005.5  2013.25  2021.0   \n",
              "Allegany     32.0  2005.5  9.380832  1990.0  1997.75  2005.5  2013.25  2021.0   \n",
              "Bronx        32.0  2005.5  9.380832  1990.0  1997.75  2005.5  2013.25  2021.0   \n",
              "Broome       32.0  2005.5  9.380832  1990.0  1997.75  2005.5  2013.25  2021.0   \n",
              "Cattaraugus  32.0  2005.5  9.380832  1990.0  1997.75  2005.5  2013.25  2021.0   \n",
              "\n",
              "            Population                ... Firearm Count          Firearm Rate  \\\n",
              "                 count          mean  ...           75%      max        count   \n",
              "County                                ...                                       \n",
              "Albany            32.0  2.996483e+05  ...        197.00    279.0         32.0   \n",
              "Allegany          32.0  4.949822e+04  ...          8.00     12.0         32.0   \n",
              "Bronx             32.0  1.334480e+06  ...       6456.00  10927.0         19.0   \n",
              "Broome            32.0  2.002506e+05  ...         59.25     92.0         32.0   \n",
              "Cattaraugus       32.0  8.084100e+04  ...         18.00     27.0         32.0   \n",
              "\n",
              "                                                                            \n",
              "                   mean         std   min      25%     50%      75%    max  \n",
              "County                                                                      \n",
              "Albany        55.825000   16.205435  35.3   41.475   51.35   65.525   89.6  \n",
              "Allegany      11.234375    6.717460   2.0    6.000    9.15   16.225   25.0  \n",
              "Bronx        352.584211  304.747834  79.3  123.800  188.90  537.100  906.5  \n",
              "Broome        23.643750   10.329567   6.1   15.625   22.05   30.275   48.9  \n",
              "Cattaraugus   16.390625    8.152631   3.5    8.200   16.15   21.450   35.7  \n",
              "\n",
              "[5 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c34969fb-a2a0-4fc1-a0cd-cddfabbf3e4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">Year</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Population</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Firearm Count</th>\n",
              "      <th colspan=\"8\" halign=\"left\">Firearm Rate</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>...</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>County</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Albany</th>\n",
              "      <td>32.0</td>\n",
              "      <td>2005.5</td>\n",
              "      <td>9.380832</td>\n",
              "      <td>1990.0</td>\n",
              "      <td>1997.75</td>\n",
              "      <td>2005.5</td>\n",
              "      <td>2013.25</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2.996483e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>197.00</td>\n",
              "      <td>279.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>55.825000</td>\n",
              "      <td>16.205435</td>\n",
              "      <td>35.3</td>\n",
              "      <td>41.475</td>\n",
              "      <td>51.35</td>\n",
              "      <td>65.525</td>\n",
              "      <td>89.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Allegany</th>\n",
              "      <td>32.0</td>\n",
              "      <td>2005.5</td>\n",
              "      <td>9.380832</td>\n",
              "      <td>1990.0</td>\n",
              "      <td>1997.75</td>\n",
              "      <td>2005.5</td>\n",
              "      <td>2013.25</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>4.949822e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>8.00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>11.234375</td>\n",
              "      <td>6.717460</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.000</td>\n",
              "      <td>9.15</td>\n",
              "      <td>16.225</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bronx</th>\n",
              "      <td>32.0</td>\n",
              "      <td>2005.5</td>\n",
              "      <td>9.380832</td>\n",
              "      <td>1990.0</td>\n",
              "      <td>1997.75</td>\n",
              "      <td>2005.5</td>\n",
              "      <td>2013.25</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1.334480e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>6456.00</td>\n",
              "      <td>10927.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>352.584211</td>\n",
              "      <td>304.747834</td>\n",
              "      <td>79.3</td>\n",
              "      <td>123.800</td>\n",
              "      <td>188.90</td>\n",
              "      <td>537.100</td>\n",
              "      <td>906.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Broome</th>\n",
              "      <td>32.0</td>\n",
              "      <td>2005.5</td>\n",
              "      <td>9.380832</td>\n",
              "      <td>1990.0</td>\n",
              "      <td>1997.75</td>\n",
              "      <td>2005.5</td>\n",
              "      <td>2013.25</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2.002506e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>59.25</td>\n",
              "      <td>92.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>23.643750</td>\n",
              "      <td>10.329567</td>\n",
              "      <td>6.1</td>\n",
              "      <td>15.625</td>\n",
              "      <td>22.05</td>\n",
              "      <td>30.275</td>\n",
              "      <td>48.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cattaraugus</th>\n",
              "      <td>32.0</td>\n",
              "      <td>2005.5</td>\n",
              "      <td>9.380832</td>\n",
              "      <td>1990.0</td>\n",
              "      <td>1997.75</td>\n",
              "      <td>2005.5</td>\n",
              "      <td>2013.25</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>8.084100e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>18.00</td>\n",
              "      <td>27.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>16.390625</td>\n",
              "      <td>8.152631</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.200</td>\n",
              "      <td>16.15</td>\n",
              "      <td>21.450</td>\n",
              "      <td>35.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  80 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c34969fb-a2a0-4fc1-a0cd-cddfabbf3e4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c34969fb-a2a0-4fc1-a0cd-cddfabbf3e4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c34969fb-a2a0-4fc1-a0cd-cddfabbf3e4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "CityName.describe().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgPyX3KkP9SN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "413763b5-6ad6-48dc-cfcd-0fad8a412d71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Year    Population  Index Count   Index Rate  Violent Count  \\\n",
              "County                                                                    \n",
              "New York  2005.5  1.577242e+06  83198.81250  5385.656250    16210.09375   \n",
              "Albany    2005.5  2.996483e+05  11885.68750  3983.981250     1345.09375   \n",
              "Monroe    2005.5  7.349208e+05  28796.59375  3932.553125     2632.84375   \n",
              "Bronx     2005.5  1.334480e+06  50209.46875  3882.415625    16991.06250   \n",
              "Erie      2005.5  9.387666e+05  35505.62500  3762.203125     5068.65625   \n",
              "\n",
              "          Violent Rate  Property Count  Property Rate  Firearm Count  \\\n",
              "County                                                                 \n",
              "New York   1051.328125     66988.71875    4334.321875    3752.368421   \n",
              "Albany      450.262500     10540.59375    3533.734375     167.406250   \n",
              "Monroe      358.665625     26163.75000    3573.871875     908.156250   \n",
              "Bronx      1311.468750     33218.40625    2570.950000    4359.315789   \n",
              "Erie        537.046875     30436.96875    3225.156250    1160.062500   \n",
              "\n",
              "          Firearm Rate  \n",
              "County                  \n",
              "New York    249.131579  \n",
              "Albany       55.825000  \n",
              "Monroe      123.706250  \n",
              "Bronx       352.584211  \n",
              "Erie        123.531250  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0df468ec-7d07-45d3-8d92-aea758735c06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Population</th>\n",
              "      <th>Index Count</th>\n",
              "      <th>Index Rate</th>\n",
              "      <th>Violent Count</th>\n",
              "      <th>Violent Rate</th>\n",
              "      <th>Property Count</th>\n",
              "      <th>Property Rate</th>\n",
              "      <th>Firearm Count</th>\n",
              "      <th>Firearm Rate</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>County</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New York</th>\n",
              "      <td>2005.5</td>\n",
              "      <td>1.577242e+06</td>\n",
              "      <td>83198.81250</td>\n",
              "      <td>5385.656250</td>\n",
              "      <td>16210.09375</td>\n",
              "      <td>1051.328125</td>\n",
              "      <td>66988.71875</td>\n",
              "      <td>4334.321875</td>\n",
              "      <td>3752.368421</td>\n",
              "      <td>249.131579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Albany</th>\n",
              "      <td>2005.5</td>\n",
              "      <td>2.996483e+05</td>\n",
              "      <td>11885.68750</td>\n",
              "      <td>3983.981250</td>\n",
              "      <td>1345.09375</td>\n",
              "      <td>450.262500</td>\n",
              "      <td>10540.59375</td>\n",
              "      <td>3533.734375</td>\n",
              "      <td>167.406250</td>\n",
              "      <td>55.825000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Monroe</th>\n",
              "      <td>2005.5</td>\n",
              "      <td>7.349208e+05</td>\n",
              "      <td>28796.59375</td>\n",
              "      <td>3932.553125</td>\n",
              "      <td>2632.84375</td>\n",
              "      <td>358.665625</td>\n",
              "      <td>26163.75000</td>\n",
              "      <td>3573.871875</td>\n",
              "      <td>908.156250</td>\n",
              "      <td>123.706250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bronx</th>\n",
              "      <td>2005.5</td>\n",
              "      <td>1.334480e+06</td>\n",
              "      <td>50209.46875</td>\n",
              "      <td>3882.415625</td>\n",
              "      <td>16991.06250</td>\n",
              "      <td>1311.468750</td>\n",
              "      <td>33218.40625</td>\n",
              "      <td>2570.950000</td>\n",
              "      <td>4359.315789</td>\n",
              "      <td>352.584211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Erie</th>\n",
              "      <td>2005.5</td>\n",
              "      <td>9.387666e+05</td>\n",
              "      <td>35505.62500</td>\n",
              "      <td>3762.203125</td>\n",
              "      <td>5068.65625</td>\n",
              "      <td>537.046875</td>\n",
              "      <td>30436.96875</td>\n",
              "      <td>3225.156250</td>\n",
              "      <td>1160.062500</td>\n",
              "      <td>123.531250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0df468ec-7d07-45d3-8d92-aea758735c06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0df468ec-7d07-45d3-8d92-aea758735c06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0df468ec-7d07-45d3-8d92-aea758735c06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "CityName.mean().sort_values(by=\"CityName\",ascending=False).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3DKUD6UQOY7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "CityName.size().sort_values(ascending=False).plot.bar()\n",
        "plt.xticks(rotation=50)\n",
        "plt.xlabel(\"Highway Name\")\n",
        "plt.ylabel(\"State Name\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9kUwzoiSZxP"
      },
      "outputs": [],
      "source": [
        "#start with one review:\n",
        "text=df.description[0]\n",
        "\n",
        "#create and generate a word cloud image:\n",
        "wordcloud=WordCloud().generate(text)\n",
        "\n",
        "#Display the generated image:\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKNwRsBvS54b"
      },
      "outputs": [],
      "source": [
        "#lower max_font_size, change the maximum number of word and light the background:\n",
        "\n",
        "wordcloud=WordCloud(max_font_size=50,max_words=100,background_color=\"white\").generate(text)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NczTT8qGVZTH"
      },
      "outputs": [],
      "source": [
        "text=\" \".join(review for review in df.description)\n",
        "print(\"There are {} words in teh combination of all reviews.\". format(len(text)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGUqJ0-_Vyx6"
      },
      "outputs": [],
      "source": [
        "#Create stopword list:\n",
        "stopwords=set(STOPWORDS)\n",
        "stopwords.update([\"North\",\"West\", \"South\", \"East\"])\n",
        "\n",
        "#Generate a word cloud image\n",
        "wordcloud=WordCloud(stopwords=stopwords,background_color=\"white\").generate(text)\n",
        "\n",
        "#Display the generated image:\n",
        "#the matplotlib way:\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llRf9bvyXXVJ"
      },
      "outputs": [],
      "source": [
        "wine_mask=np.array(Image.open(\"wine_mask.png\"))\n",
        "wine_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5hvfw9iYtDz"
      },
      "outputs": [],
      "source": [
        "def transform_format(val):\n",
        "  if val==0:\n",
        "    return 255\n",
        "  else:\n",
        "      return val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYd5RP1uZFxU"
      },
      "outputs": [],
      "source": [
        "#Transform your mask into a new one that will work with the function:\n",
        "transformed_wine_mask=np.ndarray((wine_mask.shape[0],wine_mask.shape[1]),np.int32)\n",
        "\n",
        "for i in range(len(wine_mask)):\n",
        "  transformed_wine_mask[i]=list(map(transform_format,wine_mask[i]))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc0ho0wwZlvY"
      },
      "outputs": [],
      "source": [
        "#Check the expected result of your mask\n",
        "transformed_wine_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY71Et-NaKFq"
      },
      "outputs": [],
      "source": [
        "#Create a word cloud image\n",
        "wc=WordCloud(background_color=\"white\", max_words=1000, mask=transformed_wine_mask,stopwords=stopwords,contour_width=3,contour_color='firebrick')\n",
        "\n",
        "#Generate a wordcloud\n",
        "wc.generate(text)\n",
        "\n",
        "#store to file\n",
        "wc.to_file(\"wine.png\")\n",
        "\n",
        "#show\n",
        "plt.figure(figsize=[20,10])\n",
        "plt.imshow(wc,interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUNQrDzhPMCU"
      },
      "source": [
        "# SciKit-Learn for Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhFbNYqEaVsH"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "news=fetch_20newsgroups(subset='all')\n",
        "\n",
        "print(len(news.data))\n",
        "#18846\n",
        "\n",
        "print(len(news.target_names))\n",
        "#20\n",
        "\n",
        "print(news.target_names)\n",
        "# ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
        "\n",
        "for text, num_label in zip(news.data[:10],news.target[:10]):\n",
        "  print('[%s]:\\t\\t\"%s...\"'%(news.target_names[num_label],text[:100].split('\\n')[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhprw45iczo4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train(classifier, X,y):\n",
        "  X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state=33)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  print(\"Accuracy:%s\"%classifier.score(X_test,y_test))\n",
        "  return classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7yXF-krjunD"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "trial1=Pipeline([('vectorizer',TfidfVectorizer()),\n",
        "                 ('classifier', MultinomialNB()),\n",
        "])\n",
        "\n",
        "train(trial1,news.data,news.target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_l43HUnqwxn"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "trial2=Pipeline([\n",
        "                 ('vectorizer', TfidfVectorizer(stop_words=stopwords.words('english'))),\n",
        "                 ('classifier', MultinomialNB()),              \n",
        "                 ])\n",
        "train(trial2,news.data,news.target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-xLWXw9sFb4"
      },
      "outputs": [],
      "source": [
        "trial3=Pipeline([\n",
        "                 ('vectorizer', TfidfVectorizer(stop_words=stopwords.words('english'))),\n",
        "                 ('classifier', MultinomialNB(alpha=0.05)),\n",
        "                 ])\n",
        "\n",
        "train(trial3,news.data,news.target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB5-KFK4s136"
      },
      "outputs": [],
      "source": [
        "trial4=Pipeline([\n",
        "                ('vectorizer', TfidfVectorizer(stop_words=stopwords.words('english'),\n",
        "                                               min_df=5)),\n",
        "                ('classifier', MultinomialNB(alpha=0.05)),                               \n",
        "                ])\n",
        "train(trial4,news.data,news.target)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}