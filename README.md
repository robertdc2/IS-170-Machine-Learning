# Decision Tree & Random Forests

 The Decision Tree algorithm is a machine learning technique used for both classification and regression tasks. It constructs a tree-like model where each internal node represents a feature, and each leaf node represents a class label or a predicted value. The algorithm recursively splits the data based on the selected features, aiming to maximize the information gain or minimize impurity at each split. This allows decision trees to make decisions based on a series of if-else conditions, providing interpretable and easy-to-understand models. Random Forests combine multiple decision trees to form an ensemble model. Each tree is trained on a random subset of the data, and the final prediction is made by aggregating the predictions of all the trees. Random Forests improve accuracy, handle high-dimensional data well, and reduce overfitting. 
